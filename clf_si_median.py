print("clf_si_median - active")

# === –ò–º–ø–æ—Ä—Ç—ã ===
import os
import joblib
import shap
import logging
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from sklearn.base import clone

from sklearn.metrics import precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix, accuracy_score, roc_curve
from sklearn.ensemble import RandomForestClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.feature_selection import SelectKBest, mutual_info_classif, SelectFromModel
from sklearn.model_selection import (
    GridSearchCV, StratifiedKFold, cross_val_score, cross_val_predict, train_test_split
)
from sklearn.preprocessing import StandardScaler, RobustScaler
from sklearn.pipeline import Pipeline, make_pipeline
from sklearn.ensemble import StackingClassifier
from catboost import CatBoostClassifier
from xgboost import XGBClassifier
from utils import (
    # –≠—Ç–∏ —Ñ—É–Ω–∫—Ü–∏–∏ –ø—Ä–µ–¥–ø–æ–ª–∞–≥–∞—é—Ç—Å—è —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–º–∏ –≤ –≤–∞—à–µ–º utils.py
    # load_prepared_data,
    # save_model_artifacts,
    # setup_logging,
    get_logger,
    # plot_roc_curve,
    PLOTS_DIR,
    RANDOM_STATE,
    N_SPLITS_CV
)


# === –õ–æ–≥–≥–∏—Ä–æ–≤–∞–Ω–∏–µ ===
logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s - %(name)s - %(levelname)s - %(message)s"
)
logger = logging.getLogger(__name__)

def run_clf_si_median():

    # === –ö–æ–Ω—Å—Ç–∞–Ω—Ç—ã ===
    # RANDOM_STATE = 42 # –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –∏–∑ –∏–º–ø–æ—Ä—Ç–∞
    # N_SPLITS_CV = 5 # –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –∏–∑ –∏–º–ø–æ—Ä—Ç–∞
    N_TOP_FEATURES_TO_SELECT = 45
    TASK_NAME = "clf_si_median"
    DATA_FILE = "data/eda_gen/data_final.csv"
    # FEATURE_FILE = "data/eda_gen/features/clf_SI_gt_median.txt" # –ù–µ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è, —Ç.–∫. –æ—Ç–±–æ—Ä –≤–Ω—É—Ç—Ä–∏
    SCALE_METHODS = {"standard": StandardScaler(), "robust": RobustScaler()}
    TASK_PLOTS_DIR = os.path.join(PLOTS_DIR, "classification", f"{TASK_NAME}_mi_top{N_TOP_FEATURES_TO_SELECT}_tuned_stack")
    MODELS_DIR = f"models/{TASK_NAME}"
    FEATURES_DIR = "features"

    os.makedirs(TASK_PLOTS_DIR, exist_ok=True)
    os.makedirs(MODELS_DIR, exist_ok=True)
    os.makedirs(FEATURES_DIR, exist_ok=True)

    # === –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö ===
    df = pd.read_csv(DATA_FILE)
    
    # === –§–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–∏–µ —Ç–∞—Ä–≥–µ—Ç–∞ ===
    if "SI_corrected" not in df.columns:
        logger.error("–ö–æ–ª–æ–Ω–∫–∞ 'SI_corrected' –Ω–µ –Ω–∞–π–¥–µ–Ω–∞ –≤ –¥–∞–Ω–Ω—ã—Ö")
        return # –ò–ó–ú–ï–ù–ï–ù–û: exit() –Ω–∞ return

    median_val = df["SI_corrected"].median()
    y = (df["SI_corrected"] > median_val).astype(int)
    y.name = "target"
    logger.info(f"–¶–µ–ª—å: SI_gt_median (–±–∏–Ω–∞—Ä–Ω—ã–π –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä), –ë–∞–ª–∞–Ω—Å –∫–ª–∞—Å—Å–æ–≤:\n{y.value_counts(normalize=True).rename('proportion')}")

    # === –£–¥–∞–ª–µ–Ω–∏–µ —Ü–µ–ª–µ–≤–æ–π –ø–µ—Ä–µ–º–µ–Ω–Ω–æ–π –∏ –ø–æ—Ç–µ–Ω—Ü–∏–∞–ª—å–Ω—ã—Ö —É—Ç–µ—á–µ–∫ ===
    forbidden_cols = [
        "CC50", "CC50_mM", "CC50_nM", "log_CC50", "log1p_CC50", "log1p_CC50_nM", "CC50_gt_median",
        "IC50", "IC50_mM", "IC50_nM", "log_IC50", "log1p_IC50", "log1p_IC50_nM", "IC50_gt_median",
        "SI", "SI_corrected", "log_SI", "log1p_SI", "log1p_SI_corrected",
        "SI_original", "SI_diff", "SI_diff_check", "SI_check", "SI_gt_median", "SI_gt_8",
        "ratio_IC50_CC50", "Unnamed: 0"
    ]
    removed_cols = [col for col in forbidden_cols if col in df.columns]
    X_all = df.drop(columns=removed_cols)
    X_all = X_all.select_dtypes(include="number").copy()
    logger.info(f"‚úÖ –£–¥–∞–ª–µ–Ω—ã –ø–æ—Ç–µ–Ω—Ü–∏–∞–ª—å–Ω–æ —É—Ç–µ—á–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏: {removed_cols}")

    # === –û—Ç–±–æ—Ä –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –ø–æ Mutual Information ===
    logger.info("–û—Ç–±–æ—Ä –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –ø–æ Mutual Information (MI)...")
    selector = SelectKBest(score_func=mutual_info_classif, k=N_TOP_FEATURES_TO_SELECT)
    selector.fit(X_all, y)
    
    # –ò–°–ü–†–ê–í–õ–ï–ù–ò–ï: –°—Ä–∞–∑—É —Å–æ–∑–¥–∞–µ–º DataFrame X_df –∏ —Ä–∞–±–æ—Ç–∞–µ–º —Ç–æ–ª—å–∫–æ —Å –Ω–∏–º
    selected_features = X_all.columns[selector.get_support()].tolist()
    X_df = X_all[selected_features].copy()
    logger.info(f"‚úÖ –û—Ç–æ–±—Ä–∞–Ω–æ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –ø–æ MI: {len(selected_features)} –∏–∑ {X_all.shape[1]}")

    # === A/B —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –¥–≤—É—Ö —Å–∫–µ–π–ª–µ—Ä–æ–≤ ===
    logger.info("üîç A/B-—Ç–µ—Å—Ç —Å–∫–µ–π–ª–µ—Ä–æ–≤: StandardScaler vs RobustScaler...")
    cv = StratifiedKFold(n_splits=N_SPLITS_CV, shuffle=True, random_state=RANDOM_STATE)
    scalers = {"StandardScaler": StandardScaler(), "RobustScaler": RobustScaler()}
    best_scaler_name, best_roc_auc, best_scaler = None, -np.inf, None
    for name, scaler in scalers.items():
        pipe = make_pipeline(scaler, CatBoostClassifier(verbose=0, random_state=RANDOM_STATE))
        roc_auc = cross_val_score(pipe, X_df, y, cv=cv, scoring="roc_auc", n_jobs=-1).mean() # –ò–°–ü–†–ê–í–õ–ï–ù–û: X -> X_df
        logger.info(f"ROC AUC ({name}): {roc_auc:.4f}")
        if roc_auc > best_roc_auc:
            best_roc_auc, best_scaler_name, best_scaler = roc_auc, name, scaler
    logger.info(f"‚úÖ –í—ã–±—Ä–∞–Ω –ª—É—á—à–∏–π —Å–∫–µ–π–ª–µ—Ä: {best_scaler_name} (ROC AUC = {best_roc_auc:.4f})")

    # === –¢—é–Ω–∏–Ω–≥ –º–æ–¥–µ–ª–µ–π ===
    class_counts = y.value_counts()
    total = len(y)
    class_weights = [total / (2 * class_counts[0]), total / (2 * class_counts[1])]

    models = {
        "catboost": {"model": CatBoostClassifier(verbose=0, random_state=RANDOM_STATE, class_weights=class_weights, l2_leaf_reg=10.0), "params": {"iterations": [200], "learning_rate": [0.01], "depth": [5]}},
        "xgboost": {"model": XGBClassifier(eval_metric="logloss", random_state=RANDOM_STATE), "params": {"n_estimators": [200, 400], "learning_rate": [0.01], "max_depth": [5], "subsample": [0.7], "colsample_bytree": [1.0]}}
    }
    
    tuned_models = []
    for name, config in models.items():
        logger.info(f"–¢—é–Ω–∏–Ω–≥ –º–æ–¥–µ–ª–∏: {name}")
        pipe = Pipeline([("scaler", best_scaler), ("classifier", config["model"])])
        grid_search_params = {'classifier__' + k: v for k, v in config["params"].items()}
        gs = GridSearchCV(pipe, grid_search_params, cv=StratifiedKFold(n_splits=N_SPLITS_CV, shuffle=True, random_state=RANDOM_STATE), scoring="roc_auc", n_jobs=-1, verbose=0)
        gs.fit(X_df, y)
        logger.info(f"Best ROC AUC {name}: {gs.best_score_:.4f}, –ü–∞—Ä–∞–º–µ—Ç—Ä—ã: {gs.best_params_}")
        tuned_models.append((name, gs.best_estimator_))

    # === –°—Ç–µ–∫–∏–Ω–≥ ===
    estimators = [("cat", dict(tuned_models)["catboost"]), ("xgb", dict(tuned_models)["xgboost"])]
    final_estimator = LogisticRegression(max_iter=1000, solver="liblinear")
    stack_model = StackingClassifier(estimators=estimators, final_estimator=final_estimator, cv=StratifiedKFold(n_splits=N_SPLITS_CV, shuffle=True, random_state=RANDOM_STATE), n_jobs=-1)
    stack_model.fit(X_df, y)

    # === –°—Ä–∞–≤–Ω–µ–Ω–∏–µ –∏ –≤—ã–±–æ—Ä –ª—É—á—à–µ–π –º–æ–¥–µ–ª–∏ ===
    logger.info("üìä –°—Ä–∞–≤–Ω–µ–Ω–∏–µ –º–æ–¥–µ–ª–µ–π (Stacking vs XGBoost vs CatBoost)...")
    models_to_compare = {"stack": stack_model, "xgboost": dict(tuned_models)["xgboost"], "catboost": dict(tuned_models)["catboost"]}
    results = {}
    for name, model in models_to_compare.items():
        # –ü–µ—Ä–µ–æ–±—É—á–∞—Ç—å –∑–¥–µ—Å—å –Ω–µ –æ–±—è–∑–∞—Ç–µ–ª—å–Ω–æ, –º–æ–¥–µ–ª—å —É–∂–µ –æ–±—É—á–µ–Ω–∞
        y_prob = model.predict_proba(X_df)[:, 1]
        auc = roc_auc_score(y, y_prob)
        results[name] = auc
        logger.info(f"{name} ROC AUC = {auc:.4f}")

    best_model_name = max(results, key=results.get)
    best_model = models_to_compare[best_model_name]
    logger.info(f"‚úÖ –í—ã–±—Ä–∞–Ω–∞ –ª—É—á—à–∞—è –º–æ–¥–µ–ª—å: {best_model_name.upper()} (ROC AUC = {results[best_model_name]:.4f})")
    
    # === Hold-out –≤–∞–ª–∏–¥–∞—Ü–∏—è ===
    logger.info("–ü—Ä–æ–≤–µ—Ä–∫–∞ –º–æ–¥–µ–ª–∏ –Ω–∞ –æ—Ç–ª–æ–∂–µ–Ω–Ω–æ–π –≤—ã–±–æ—Ä–∫–µ (hold-out 20%)...")
    X_train, X_test, y_train, y_test = train_test_split(X_df, y, test_size=0.2, random_state=RANDOM_STATE, stratify=y)
    best_model.fit(X_train, y_train)
    y_test_proba = best_model.predict_proba(X_test)[:, 1]
    y_test_pred = best_model.predict(X_test)
    roc_auc_holdout = roc_auc_score(y_test, y_test_proba)
    logger.info(f"=== Hold-out –º–µ—Ç—Ä–∏–∫–∏ (Test 20%) ===")
    logger.info(f"ROC AUC:  {roc_auc_holdout:.4f}")
    
    # === SHAP-–∞–Ω–∞–ª–∏–∑ –∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –∞—Ä—Ç–µ—Ñ–∞–∫—Ç–æ–≤ ===
    logger.info("SHAP-–∞–Ω–∞–ª–∏–∑...")
    # –ò–°–ü–†–ê–í–õ–ï–ù–ò–ï 2: –í—Å—è –ª–æ–≥–∏–∫–∞ SHAP –∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –ø–µ—Ä–µ—Å—Ç—Ä–æ–µ–Ω–∞ –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è –°–û–í–ú–ï–°–¢–ò–ú–´–• –∞—Ä—Ç–µ—Ñ–∞–∫—Ç–æ–≤
    model_for_shap = best_model.named_steps.get("classifier", None) # –ë–µ–∑–æ–ø–∞—Å–Ω–æ –ø–æ–ª—É—á–∞–µ–º –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä
    
    final_features = X_df.columns.tolist() # –ü–æ —É–º–æ–ª—á–∞–Ω–∏—é - –∏—Å—Ö–æ–¥–Ω—ã–µ MI-–ø—Ä–∏–∑–Ω–∞–∫–∏
    model_to_save = best_model # –ü–æ —É–º–æ–ª—á–∞–Ω–∏—é - –∏—Å—Ö–æ–¥–Ω–∞—è –ª—É—á—à–∞—è –º–æ–¥–µ–ª—å

    if isinstance(model_for_shap, StackingClassifier):
        logger.warning("‚ùå SHAP –Ω–µ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç StackingClassifier –Ω–∞–ø—Ä—è–º—É—é ‚Äî —Å–æ—Ö—Ä–∞–Ω—è–µ–º –º–æ–¥–µ–ª—å –∏ –ø—Ä–∏–∑–Ω–∞–∫–∏ –¥–æ SHAP-–æ—Ç–±–æ—Ä–∞.")
    elif model_for_shap is not None:
        try:
            X_transformed = best_model.named_steps['scaler'].fit_transform(X_df)
            explainer = shap.Explainer(model_for_shap, X_transformed)
            shap_values = explainer(X_transformed)
            
            vals = np.abs(shap_values.values).mean(0)
            feature_importance = pd.DataFrame(list(zip(X_df.columns, vals)), columns=['feature', 'importance'])
            feature_importance.sort_values(by=['importance'], ascending=False, inplace=True)
            
            # –û—Ç–±–∏—Ä–∞–µ–º –í–°–ï –ø—Ä–∏–∑–Ω–∞–∫–∏, –æ—Ç—Å–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –ø–æ SHAP
            final_features = feature_importance['feature'].tolist() 
            X_final = X_df[final_features]
            logger.info(f"üîç –§–∏–Ω–∞–ª—å–Ω–æ–µ —á–∏—Å–ª–æ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –ø–æ—Å–ª–µ SHAP-–æ—Ç–±–æ—Ä–∞: {len(final_features)}")

            # –ü–µ—Ä–µ–æ–±—É—á–∞–µ–º –ª—É—á—à—É—é –º–æ–¥–µ–ª—å –Ω–∞ —ç—Ç–æ–º —Ñ–∏–Ω–∞–ª—å–Ω–æ–º –Ω–∞–±–æ—Ä–µ
            logger.info(f"–ü–µ—Ä–µ–æ–±—É—á–µ–Ω–∏–µ –ª—É—á—à–µ–π –º–æ–¥–µ–ª–∏ ({best_model_name}) –Ω–∞ {len(final_features)} —Ñ–∏–Ω–∞–ª—å–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–∞—Ö...")
            model_to_save = clone(best_model)
            model_to_save.fit(X_final, y)

        except Exception as e:
            logger.warning(f"‚ùå SHAP-–∞–Ω–∞–ª–∏–∑ –Ω–µ –≤—ã–ø–æ–ª–Ω–µ–Ω: {e}. –°–æ—Ö—Ä–∞–Ω—è–µ–º –º–æ–¥–µ–ª—å –∏ –ø—Ä–∏–∑–Ω–∞–∫–∏ –¥–æ SHAP-–æ—Ç–±–æ—Ä–∞.")
    else:
        logger.warning("–ù–µ —É–¥–∞–ª–æ—Å—å –∏–∑–≤–ª–µ—á—å –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä –¥–ª—è SHAP. –°–æ—Ö—Ä–∞–Ω—è–µ–º –º–æ–¥–µ–ª—å –∏ –ø—Ä–∏–∑–Ω–∞–∫–∏ –¥–æ SHAP-–æ—Ç–±–æ—Ä–∞.")


    # --- –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ñ–∏–Ω–∞–ª—å–Ω—ã—Ö, —Å–æ–≤–º–µ—Å—Ç–∏–º—ã—Ö –∞—Ä—Ç–µ—Ñ–∞–∫—Ç–æ–≤ ---
    logger.info("üíæ –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –∞—Ä—Ç–µ—Ñ–∞–∫—Ç–æ–≤...")
    # 1. –°–æ—Ö—Ä–∞–Ω—è–µ–º –º–æ–¥–µ–ª—å (–ø–µ—Ä–µ–æ–±—É—á–µ–Ω–Ω—É—é –Ω–∞ SHAP-–ø—Ä–∏–∑–Ω–∞–∫–∞—Ö, –µ—Å–ª–∏ —É–¥–∞–ª–æ—Å—å)
    model_filename = f"model_{TASK_NAME}_{best_model_name}.joblib".replace(f"_mi_top{N_TOP_FEATURES_TO_SELECT}", "") # –£–±–∏—Ä–∞–µ–º –ª–∏—à–Ω–µ–µ –∏–∑ –∏–º–µ–Ω–∏
    model_path = os.path.join(MODELS_DIR, model_filename)
    joblib.dump(model_to_save, model_path)
    logger.info(f"–ú–æ–¥–µ–ª—å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞: {model_path}")

    # 2. –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ñ–∏–Ω–∞–ª—å–Ω—ã–π —Å–ø–∏—Å–æ–∫ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
    features_filename = f"selected_by_shap_{TASK_NAME}.txt"
    features_path = os.path.join(FEATURES_DIR, features_filename)
    pd.DataFrame(final_features, columns=['feature']).to_csv(features_path, index=False, header=True)
    logger.info(f"–°–æ—Ö—Ä–∞–Ω–µ–Ω–æ {len(final_features)} –ø—Ä–∏–∑–Ω–∞–∫–æ–≤: {features_path}")

    logger.info(f"‚úÖ –£—Å–ø–µ—à–Ω–æ: {os.path.basename(__file__)}")

if __name__ == "__main__":
    run_clf_si_median()