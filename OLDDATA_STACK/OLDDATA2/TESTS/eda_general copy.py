# === eda_general.py ===

# === –≠–¢–ê–ü 0: –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –æ–∫—Ä—É–∂–µ–Ω–∏—è –∏ –±–∞–∑–æ–≤–∞—è –∑–∞–≥—Ä—É–∑–∫–∞ ===

# === –ò–ú–ü–û–†–¢–´ –ò –ù–ê–°–¢–†–û–ô–ö–ò ===

# üì¶ –ë–∞–∑–æ–≤—ã–µ –±–∏–±–ª–∏–æ—Ç–µ–∫–∏
import os
import re
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import warnings
import joblib

# üß™ –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –∏ –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è
import scipy.stats as stats
from matplotlib import gridspec

# üß† ML / Feature Selection / –ú–µ—Ç—Ä–∏–∫–∏
from sklearn.impute import SimpleImputer
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split
from sklearn.feature_selection import mutual_info_regression, mutual_info_classif
from sklearn.metrics import (
    mean_squared_error, mean_absolute_error, r2_score,
    classification_report, confusion_matrix, ConfusionMatrixDisplay
)
from sklearn.dummy import DummyRegressor, DummyClassifier
from sklearn.decomposition import PCA
from sklearn.discriminant_analysis import LinearDiscriminantAnalysis

# üåê –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è –ø—Ä–æ–µ–∫—Ü–∏–π
import umap.umap_ as umap

# üõ†Ô∏è –ù–∞—Å—Ç—Ä–æ–π–∫–∏ –≤—ã–≤–æ–¥–∞ –∏ –≥—Ä–∞—Ñ–∏–∫–æ–≤
warnings.filterwarnings("ignore")
pd.set_option("display.max_columns", None)
pd.set_option("display.float_format", '{:.4f}'.format)
sns.set(style="whitegrid")

def main():

    # === –°–û–ó–î–ê–ù–ò–ï –ö–ê–¢–ê–õ–û–ì–û–í ===
    os.makedirs("data/eda_gen", exist_ok=True)
    os.makedirs("plots/eda_gen", exist_ok=True)
    os.makedirs("data/eda_gen/scaled", exist_ok=True)
    os.makedirs("data/eda_gen/features", exist_ok=True)
    os.makedirs("plots/eda_gen/projections_task/pca", exist_ok=True)
    os.makedirs("plots/eda_gen/projections_task/umap", exist_ok=True)
    os.makedirs("plots/eda_gen/projections_task/lda", exist_ok=True)
    os.makedirs("plots/eda_gen/projections_variance", exist_ok=True)
    os.makedirs("plots/eda_gen/targets/log_transform", exist_ok=True)
    os.makedirs("plots/eda_gen/targets/strip", exist_ok=True)
    os.makedirs("plots/eda_gen/classification_targets", exist_ok=True)
    os.makedirs("plots/eda_gen/classification_targets/analysis", exist_ok=True)
    os.makedirs("plots/eda_gen/classification_targets/dummy_reports", exist_ok=True)
    os.makedirs("plots/eda_gen/outliers", exist_ok=True)
    os.makedirs("plots/dummy", exist_ok=True)
    os.makedirs("plots/eda_gen/features", exist_ok=True)
    os.makedirs("plots/eda_gen/feature_importance", exist_ok=True)


    # üì• –ó–∞–≥—Ä—É–∑–∫–∞ –∏—Å—Ö–æ–¥–Ω–æ–≥–æ Excel-—Ñ–∞–π–ª–∞
    df = pd.read_excel("data/–î–∞–Ω–Ω—ã–µ_–¥–ª—è_–∫—É—Ä—Å–æ–≤–æ–∏_–ö–ª–∞—Å—Å–∏—á–µ—Å–∫–æ–µ_–ú–û.xlsx")

    # ‚úÖ –ü—É—Ç–∏ –∫ —Ñ–∏–Ω–∞–ª—å–Ω—ã–º –æ–±—ä–µ–∫—Ç–∞–º
    DATA_PATH = "data/eda_gen/data_final.csv"
    X_SCALED_PATH = "data/eda_gen/scaled/X_scaled.csv"
    SCALER_PATH = "data/eda_gen/scaled/scaler_clf.pkl"

    # üéØ –¶–µ–ª–µ–≤—ã–µ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –¥–ª—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏
    TARGET_COLUMNS = [
        "IC50_gt_median", "CC50_gt_median",
        "SI_gt_median", "SI_gt_8"
    ]

    # üö´ –ü—Ä–∏–∑–Ω–∞–∫–∏, –∫–æ—Ç–æ—Ä—ã–µ –Ω–µ–ª—å–∑—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –∫–∞–∫ —Ñ–∏—á–∏
    FORBIDDEN_COLUMNS = [
        "IC50_nM", "CC50_nM", "SI_corrected",
        "log1p_IC50_nM", "log1p_CC50_nM", "log1p_SI"
    ] + TARGET_COLUMNS

    # üñ®Ô∏è –û–±—â–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –¥–∞—Ç–∞—Å–µ—Ç–µ
    print("‚úÖ –≠–¢–ê–ü 0: –ó–∞–≥—Ä—É–∑–∫–∞ –∏ –ø–µ—Ä–≤–∏—á–Ω—ã–π –æ—Å–º–æ—Ç—Ä –¥–∞–Ω–Ω—ã—Ö")
    print("üìê –†–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å:", df.shape)
    print("üìã –ü–µ—Ä–≤—ã–µ —Å—Ç—Ä–æ–∫–∏:")
    print(df.head(3))
    print("üì¶ –¢–∏–ø—ã –¥–∞–Ω–Ω—ã—Ö:")
    print(df.dtypes.value_counts())
    print("üîç Object-–∫–æ–ª–æ–Ω–∫–∏:")
    print(df.select_dtypes(include='object').columns.tolist())
    print("üìå –î—É–±–ª–∏–∫–∞—Ç—ã:", df.duplicated().sum())
    print("üìå –°—Ç—Ä–æ–∫ —Å >20 NaN:", (df.isnull().sum(axis=1) > 20).sum())

    # üìä –ü–æ–¥—Å—á—ë—Ç NaN –ø–æ —Å—Ç–æ–ª–±—Ü–∞–º
    nan_stats = df.isnull().sum()
    nan_stats = nan_stats[nan_stats > 0].sort_values(ascending=False)
    if nan_stats.empty:
        print("‚úÖ –ü—Ä–æ–ø—É—Å–∫–æ–≤ –Ω–µ—Ç")
    else:
        print("‚ö†Ô∏è –ù–∞–π–¥–µ–Ω—ã –ø—Ä–æ–ø—É—Å–∫–∏:")
        print(nan_stats)

    print("‚úÖ –≠–¢–ê–ü 0 –∑–∞–≤–µ—Ä—à—ë–Ω: –ò–º–ø–æ—Ä—Ç—ã –∏ –∑–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö –≤—ã–ø–æ–ª–Ω–µ–Ω—ã")


    # === –≠–¢–ê–ü 1: –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ —Ü–µ–ª–µ–≤—ã—Ö –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö –∏ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ ===


    # === –®–∞–≥ 1: –û—á–∏—Å—Ç–∫–∞ –Ω–∞–∑–≤–∞–Ω–∏–π –∫–æ–ª–æ–Ω–æ–∫ ===
    df = df.drop(columns=["Unnamed: 0"], errors="ignore")
    df.columns = df.columns.str.strip().str.replace(",", "").str.replace(" ", "_")

    # === –®–∞–≥ 2: –£–¥–∞–ª–µ–Ω–∏–µ –¥—É–±–ª–∏–∫–∞—Ç–æ–≤ –∏ –ø—Ä–æ–ø—É—Å–∫–æ–≤ ===
    df = df.drop_duplicates()
    df = df.fillna(df.mean(numeric_only=True))

    # === –®–∞–≥ 3: –ü—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ –≤ –Ω–∞–Ω–æ–ú–æ–ª–∏ ===
    df["IC50_nM"] = df["IC50_mM"] * 1e6
    df["CC50_nM"] = df["CC50_mM"] * 1e6

    # === –õ–æ–≥–∞—Ä–∏—Ñ–º–∏—Ä–æ–≤–∞–Ω–∏–µ ===
    df["log1p_IC50_nM"] = np.log1p(df["IC50_nM"])
    df["log1p_CC50_nM"] = np.log1p(df["CC50_nM"])

    # === –†–∞—Å—á—ë—Ç SI –∏ –ª–æ–≥–∞—Ä–∏—Ñ–º ===
    df["SI_corrected"] = df["CC50_nM"] / df["IC50_nM"]
    df["SI_corrected"] = df["SI_corrected"].replace([np.inf, -np.inf], np.nan)
    df["log1p_SI"] = np.log1p(df["SI_corrected"])

    # === –£–¥–∞–ª–µ–Ω–∏–µ NaN –≤ –∫—Ä–∏—Ç–∏—á–Ω—ã—Ö —Ç–∞—Ä–≥–µ—Ç–∞—Ö ===
    df = df.dropna(subset=["log1p_IC50_nM", "log1p_CC50_nM", "log1p_SI"])

    # === –£–¥–∞–ª–µ–Ω–∏–µ –∏—Å—Ö–æ–¥–Ω—ã—Ö SI/IC50/CC50 –ø–æ—Å–ª–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è ===
    df = df.drop(columns=["IC50_mM", "CC50_mM", "SI"], errors="ignore")

    # === –ë–∏–Ω–∞—Ä–∏–∑–∞—Ü–∏—è —Ç–∞—Ä–≥–µ—Ç–æ–≤ ===
    df["IC50_gt_median"] = (df["IC50_nM"] > df["IC50_nM"].median()).astype(int)
    df["CC50_gt_median"] = (df["CC50_nM"] > df["CC50_nM"].median()).astype(int)
    df["SI_gt_median"] = (df["SI_corrected"] > df["SI_corrected"].median()).astype(int)
    df["SI_gt_8"] = (df["SI_corrected"] > 8).astype(int)


    # === –ò—Å—Ö–æ–¥–Ω—ã–µ –∏ –ª–æ–≥-–ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è ===
    targets = {
        "IC50": ("IC50_nM", "log1p_IC50_nM"),
        "CC50": ("CC50_nM", "log1p_CC50_nM"),
        "SI": ("SI_corrected", "log1p_SI")
    }

    # === –§—É–Ω–∫—Ü–∏—è –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏ –¥–æ/–ø–æ—Å–ª–µ ===
    def plot_comparison(before, after, label, save_name):
        fig = plt.figure(figsize=(16, 5))
        spec = gridspec.GridSpec(ncols=4, nrows=1, figure=fig)

        ax0 = fig.add_subplot(spec[0, 0])
        sns.histplot(before, kde=True, bins=30, ax=ax0, color="skyblue")
        ax0.set_title(f"{label} - –ì–∏—Å—Ç–æ–≥—Ä–∞–º–º–∞ + KDE")

        ax1 = fig.add_subplot(spec[0, 1])
        sns.boxplot(y=before, ax=ax1, color="lightgreen")
        ax1.set_title(f"{label} - Boxplot")

        ax2 = fig.add_subplot(spec[0, 2])
        stats.probplot(before, dist="norm", plot=ax2)
        ax2.set_title("QQ Plot")

        mean = before.mean()
        std = before.std()
        skew = before.skew()
        kurt = before.kurt()
        iqr = before.quantile(0.75) - before.quantile(0.25)
        val_range = (before.min(), before.max())

        stats_text = f"""
        Mean      = {mean:.3f}
        Std       = {std:.3f}
        Skewness  = {skew:.3f}
        Kurtosis  = {kurt:.3f}
        IQR       = {iqr:.3f}
        Min-Max   = {val_range[0]:.3f} ‚Üí {val_range[1]:.3f}
        """

        ax3 = fig.add_subplot(spec[0, 3])
        ax3.text(0.1, 0.5, stats_text, fontsize=12)
        ax3.axis("off")
        ax3.set_title("–°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏")

        plt.suptitle(f"{label}", fontsize=14)
        plt.tight_layout()
        plt.subplots_adjust(top=0.85)
        plt.savefig(f"plots/eda_gen/targets/log_transform/{save_name}.png")
        plt.close()

    # === –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –≥—Ä–∞—Ñ–∏–∫–æ–≤ –¥–æ/–ø–æ—Å–ª–µ –ª–æ–≥–∞—Ä–∏—Ñ–º–∏—Ä–æ–≤–∞–Ω–∏—è ===
    for name, (raw_col, log_col) in targets.items():
        plot_comparison(df[raw_col], df[raw_col], f"{name} ‚Äî –î–û –ª–æ–≥–∞—Ä–∏—Ñ–º–∏—Ä–æ–≤–∞–Ω–∏—è", f"{name}_before_log")
        plot_comparison(df[log_col], df[log_col], f"{name} ‚Äî –ü–û–°–õ–ï –ª–æ–≥–∞—Ä–∏—Ñ–º–∏—Ä–æ–≤–∞–Ω–∏—è", f"{name}_after_log")

    # === –£–¥–∞–ª–µ–Ω–∏–µ —É—Ç–µ—á–µ–∫ ===
    df = df.drop(columns=["IC50_nM", "CC50_nM", "SI_corrected"], errors="ignore")

    # === –ü—Ä–æ–≤–µ—Ä–∫–∏ ===
    print("‚úÖ –†–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å –ø–æ—Å–ª–µ –æ–±—Ä–∞–±–æ—Ç–∫–∏:", df.shape)
    print("\nüìä –û–ø–∏—Å–∞–Ω–∏–µ –ª–æ–≥-—Ç–∞—Ä–≥–µ—Ç–æ–≤:")
    print(df[["log1p_IC50_nM", "log1p_CC50_nM", "log1p_SI"]].describe())

    print("\nüìä –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –∫–ª–∞—Å—Å–æ–≤:")
    for col in ["IC50_gt_median", "CC50_gt_median", "SI_gt_median", "SI_gt_8"]:
        print(f"{col}:")
        print(df[col].value_counts(normalize=True).rename_axis("class").reset_index(name="fraction"))
        print()

    # === –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç ===
    df.to_csv("data/eda_gen/data_clean.csv", index=False)

    # === –ü—Ä–æ–≤–µ—Ä–∫–∞ –ø—Ä–æ–ø—É—Å–∫–æ–≤ ===
    nan_counts = df.isnull().sum()
    nan_counts = nan_counts[nan_counts > 0]

    if nan_counts.empty:
        print("‚úÖ –ü—Ä–æ–ø—É—â–µ–Ω–Ω—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π –≤ –¥–∞—Ç–∞—Ñ—Ä–µ–π–º–µ –ù–ï–¢.")
    else:
        print("üß® –ù–∞–π–¥–µ–Ω—ã –ø—Ä–æ–ø—É—Å–∫–∏:")
        print(nan_counts.sort_values(ascending=False))

    print("üíæ –°–æ—Ö—Ä–∞–Ω–µ–Ω–æ: data/eda_gen/data_clean.csv")






    # === –≠–¢–ê–ü 2: –ê–Ω–∞–ª–∏–∑ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–π –ª–æ–≥-—Ç–∞—Ä–≥–µ—Ç–æ–≤ + —É–¥–∞–ª–µ–Ω–∏–µ –≤—ã–±—Ä–æ—Å–æ–≤ ===


    # === –ù–∞—Å—Ç—Ä–æ–π–∫–∏ ===
    df = pd.read_csv("data/eda_gen/data_clean.csv")

    target_cols = ["log1p_IC50_nM", "log1p_CC50_nM", "log1p_SI"]

    # === –§—É–Ω–∫—Ü–∏–∏ ===
    def plot_distribution(col, data, stage, path_prefix):
        fig = plt.figure(figsize=(16, 5))
        spec = gridspec.GridSpec(ncols=4, nrows=1, figure=fig)

        ax0 = fig.add_subplot(spec[0, 0])
        sns.histplot(data[col], kde=True, bins=30, ax=ax0, color="skyblue")
        ax0.set_title(f"{col} ‚Äî Histogram ({stage})")

        ax1 = fig.add_subplot(spec[0, 1])
        sns.boxplot(y=data[col], ax=ax1, color="lightgreen")
        ax1.set_title(f"{col} ‚Äî Boxplot ({stage})")

        ax2 = fig.add_subplot(spec[0, 2])
        stats.probplot(data[col], dist="norm", plot=ax2)
        ax2.set_title(f"{col} ‚Äî QQ Plot ({stage})")

        ax3 = fig.add_subplot(spec[0, 3])
        stats_text = f"""
        Mean      = {data[col].mean():.3f}
        Std       = {data[col].std():.3f}
        Skewness  = {data[col].skew():.3f}
        Kurtosis  = {data[col].kurt():.3f}
        IQR       = {(data[col].quantile(0.75) - data[col].quantile(0.25)):.3f}
        Min-Max   = {data[col].min():.3f} ‚Üí {data[col].max():.3f}
        """
        ax3.text(0.1, 0.5, stats_text, fontsize=12)
        ax3.axis("off")
        ax3.set_title("–°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞")

        plt.suptitle(f"EDA: {col} ({stage})", fontsize=14)
        plt.tight_layout()
        plt.subplots_adjust(top=0.85)
        plt.savefig(f"{path_prefix}/{col}_distribution_{stage}.png")
        plt.close()

    def remove_outliers_iqr(df, col):
        q1 = df[col].quantile(0.25)
        q3 = df[col].quantile(0.75)
        iqr = q3 - q1
        lower = q1 - 1.5 * iqr
        upper = q3 + 1.5 * iqr
        before = df.shape[0]
        df = df[(df[col] >= lower) & (df[col] <= upper)]
        after = df.shape[0]
        print(f"üßπ {col}: —É–¥–∞–ª–µ–Ω–æ {before - after} –≤—ã–±—Ä–æ—Å–æ–≤ –ø–æ IQR")
        return df

    # === –≠–¢–ê–ü 2: –ê–Ω–∞–ª–∏–∑ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–π, –≤—ã–±—Ä–æ—Å–æ–≤, DummyRegressor –∏ stripplot ===


    # === –ö–æ–Ω—Å—Ç–∞–Ω—Ç—ã ===
    target_cols = ["log1p_IC50_nM", "log1p_CC50_nM", "log1p_SI"]
    binary_targets = ["IC50_gt_median", "CC50_gt_median", "SI_gt_median", "SI_gt_8"]
    forbidden_cols = [
        "IC50_nM", "CC50_nM", "SI_corrected",
        "log1p_IC50_nM", "log1p_CC50_nM", "log1p_SI",
        "IC50_gt_median", "CC50_gt_median", "SI_gt_median", "SI_gt_8"
    ]


    # === –§—É–Ω–∫—Ü–∏–∏ ===

    def get_stats_text(series):
        return f"""
        Mean      = {series.mean():.3f}
        Std       = {series.std():.3f}
        Skewness  = {series.skew():.3f}
        Kurtosis  = {series.kurt():.3f}
        IQR       = {series.quantile(0.75) - series.quantile(0.25):.3f}
        Min-Max   = {series.min():.3f} ‚Üí {series.max():.3f}
        """

    def get_quantiles_robust(series):
        skew = series.skew()
        kurt = series.kurt()
        n = len(series)
        if n < 200:
            return 0.25, 0.75, 1.5, "IQR"
        if abs(skew) > 2 or kurt > 5:
            return None, None, 3, "MAD"
        if abs(skew) > 1.2 or kurt > 2.5:
            return 0.2, 0.6, 1.0, "IQR"
        if abs(skew) > 0.5 or kurt > 1.5:
            return 0.22, 0.68, 1.5, "IQR"
        return 0.25, 0.75, 1.5, "IQR"

    def plot_ecdf(series, title, path):
        x = np.sort(series)
        y = np.arange(1, len(x) + 1) / len(x)
        plt.figure(figsize=(5, 4))
        plt.plot(x, y, marker='.', linestyle='none', color='blue')
        plt.xlabel(title)
        plt.ylabel("–î–æ–ª—è ‚â§ –∑–Ω–∞—á–µ–Ω–∏—è")
        plt.title(f"ECDF: {title}")
        plt.grid(True)
        plt.savefig(path)
        plt.close()

    # === 2.1: –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è –∏ —É–¥–∞–ª–µ–Ω–∏–µ –≤—ã–±—Ä–æ—Å–æ–≤ ===
    for col in target_cols:
        print(f"\nüìä –û–±—Ä–∞–±–æ—Ç–∫–∞ –ø–µ—Ä–µ–º–µ–Ω–Ω–æ–π: {col}")

        # –î–æ —É–¥–∞–ª–µ–Ω–∏—è –≤—ã–±—Ä–æ—Å–æ–≤
        fig = plt.figure(figsize=(24, 5))
        spec = gridspec.GridSpec(ncols=4, nrows=1, figure=fig)

        ax0 = fig.add_subplot(spec[0, 0])
        sns.histplot(df[col], kde=True, bins=30, color="skyblue", ax=ax0)
        ax0.set_title(f"{col} ‚Äî Histogram (Before)")

        ax1 = fig.add_subplot(spec[0, 1])
        sns.boxplot(y=df[col], color="salmon", ax=ax1)
        ax1.set_title(f"{col} ‚Äî Boxplot (Before)")

        ax2 = fig.add_subplot(spec[0, 2])
        stats.probplot(df[col], dist="norm", plot=ax2)
        ax2.set_title(f"{col} ‚Äî QQ Plot (Before)")

        ax3 = fig.add_subplot(spec[0, 3])
        ax3.text(0.05, 0.5, get_stats_text(df[col]), fontsize=12, verticalalignment='center')
        ax3.axis("off")
        ax3.set_title("Stats (Before)")

        plt.tight_layout()
        plt.savefig(f"plots/eda_gen/outliers/{col}_before_outliers.png")
        plt.close()

        # ECDF –¥–æ
        plot_ecdf(df[col], f"{col} (Before)", f"plots/eda_gen/outliers/{col}_ecdf_before.png")

        # –£–¥–∞–ª–µ–Ω–∏–µ –≤—ã–±—Ä–æ—Å–æ–≤ –ø–æ —Ñ–∏–∫—Å–∏—Ä–æ–≤–∞–Ω–Ω—ã–º –∫–≤–∞–Ω—Ç–∏–ª—è–º
        Q1 = df[col].quantile(0.22)
        Q3 = df[col].quantile(0.68)
        IQR = Q3 - Q1
        lower = Q1 - 1.5 * IQR
        upper = Q3 + 1.5 * IQR
        method = "IQR"

        outliers = df[(df[col] < lower) | (df[col] > upper)]
        print(f"üß® –£–¥–∞–ª—è–µ—Ç—Å—è –≤—ã–±—Ä–æ—Å–æ–≤ –ø–æ {col}: {outliers.shape[0]} —Å—Ç—Ä–æ–∫ (–º–µ—Ç–æ–¥: {method}, –º–Ω–æ–∂–∏—Ç–µ–ª—å=1.5)")
        print(f"  ‚Üí –ö–≤–∞–Ω—Ç–∏–ª–∏: Q1=0.22, Q3=0.68")

        outliers.to_csv(f"plots/eda_gen/outliers/removed_{col}.csv", index=False)
        df = df[(df[col] >= lower) & (df[col] <= upper)]

        # –ü–æ—Å–ª–µ —É–¥–∞–ª–µ–Ω–∏—è –≤—ã–±—Ä–æ—Å–æ–≤
        fig = plt.figure(figsize=(24, 5))
        spec = gridspec.GridSpec(ncols=4, nrows=1, figure=fig)

        ax0 = fig.add_subplot(spec[0, 0])
        sns.histplot(df[col], kde=True, bins=30, color="lightgreen", ax=ax0)
        ax0.set_title(f"{col} ‚Äî Histogram (After)")

        ax1 = fig.add_subplot(spec[0, 1])
        sns.boxplot(y=df[col], color="lightblue", ax=ax1)
        ax1.set_title(f"{col} ‚Äî Boxplot (After)")

        ax2 = fig.add_subplot(spec[0, 2])
        stats.probplot(df[col], dist="norm", plot=ax2)
        ax2.set_title(f"{col} ‚Äî QQ Plot (After)")

        ax3 = fig.add_subplot(spec[0, 3])
        ax3.text(0.05, 0.5, get_stats_text(df[col]), fontsize=12, verticalalignment='center')
        ax3.axis("off")
        ax3.set_title("Stats (After)")

        plt.tight_layout()
        plt.savefig(f"plots/eda_gen/outliers/{col}_after_outliers.png")
        plt.close()

        # ECDF –ø–æ—Å–ª–µ
        plot_ecdf(df[col], f"{col} (After)", f"plots/eda_gen/outliers/{col}_ecdf_after.png")

    # === 2.2: Dummy Regressor ===
    for target in target_cols:
        print(f"\nüìä Dummy Regressor Report ‚Äî {target}")

        y = df[target]
        X = df.drop(columns=forbidden_cols, errors="ignore").select_dtypes(include="number")

        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

        model = DummyRegressor(strategy="mean")
        model.fit(X_train, y_train)
        y_pred = model.predict(X_test)

        rmse = np.sqrt(mean_squared_error(y_test, y_pred))
        mae = mean_absolute_error(y_test, y_pred)
        r2 = r2_score(y_test, y_pred)

        print(f"RMSE: {rmse:.4f}")
        print(f"MAE:  {mae:.4f}")
        print(f"R¬≤:   {r2:.4f}")

        # Scatter
        plt.figure(figsize=(6, 6))
        plt.scatter(y_test, y_pred, alpha=0.6, edgecolors="k")
        plt.plot([y.min(), y.max()], [y.min(), y.max()], linestyle="--", color="red")
        plt.xlabel("True Values")
        plt.ylabel("Predicted")
        plt.title(f"Dummy: {target}")
        plt.tight_layout()
        plt.savefig(f"plots/dummy/{target}_scatter.png")
        plt.close()

        # Residuals
        residuals = y_test - y_pred
        plt.figure(figsize=(6, 4))
        plt.hist(residuals, bins=30, color="skyblue", edgecolor="black")
        plt.axvline(0, color="red", linestyle="--")
        plt.xlabel("Prediction Error")
        plt.ylabel("Count")
        plt.title(f"Residuals: {target}")
        plt.tight_layout()
        plt.savefig(f"plots/dummy/{target}_residuals.png")
        plt.close()

    # === 2.3: Stripplot –ø–æ –±–∏–Ω–∞—Ä–Ω—ã–º –∫–ª–∞—Å—Å–∞–º ===
    for hue_target in binary_targets:
        for reg_col in target_cols:
            plt.figure(figsize=(8, 4))
            sns.stripplot(
                x=df[hue_target].astype(str),
                y=df[reg_col],
                jitter=True,
                alpha=0.5,
                palette="Set2",
                edgecolor="gray",
                linewidth=0.3
            )
            plt.title(f"{reg_col} –ø–æ –∫–ª–∞—Å—Å–∞–º {hue_target}")
            plt.xlabel(hue_target)
            plt.ylabel(reg_col)
            plt.grid(True, linestyle="--", alpha=0.3)
            plt.tight_layout()
            plt.savefig(f"plots/eda_gen/targets/strip/{reg_col}_by_{hue_target}.png")
            plt.close()







    # === –≠–¢–ê–ü 3: –ê–Ω–∞–ª–∏–∑ –±–∏–Ω–∞—Ä–Ω—ã—Ö –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–æ–Ω–Ω—ã—Ö –º–µ—Ç–æ–∫ ===
    print("\n=== –≠–¢–ê–ü 3: –ê–Ω–∞–ª–∏–∑ –±–∏–Ω–∞—Ä–Ω—ã—Ö –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–æ–Ω–Ω—ã—Ö –º–µ—Ç–æ–∫ ===")




    # === –ë–∏–Ω–∞—Ä–Ω—ã–µ —Ç–∞—Ä–≥–µ—Ç—ã ===
    binary_targets = ["IC50_gt_median", "CC50_gt_median", "SI_gt_median", "SI_gt_8"]

    # === –≠–¢–ê–ü 3.1: –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –∫–ª–∞—Å—Å–æ–≤ ===
    for col in binary_targets:
        counts = df[col].value_counts().sort_index()
        percentages = counts / counts.sum() * 100

        plt.figure(figsize=(5, 4))
        ax = sns.barplot(x=counts.index.astype(str), y=counts.values, palette="Set2")
        for i, (v, p) in enumerate(zip(counts.values, percentages.values)):
            ax.text(i, v + 2, f"{v} ({p:.1f}%)", ha="center", fontsize=10)
        plt.title(f"–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –∫–ª–∞—Å—Å–æ–≤: {col}")
        plt.xlabel("–ö–ª–∞—Å—Å")
        plt.ylabel("–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ")
        plt.tight_layout()
        plt.savefig(f"plots/eda_gen/classification_targets/{col}_distribution.png")
        plt.close()

        print(f"üìä {col}:")
        for cls in counts.index:
            print(f"  –ö–ª–∞—Å—Å {cls}: {counts[cls]} ({percentages[cls]:.2f}%)")
        print("-" * 50)

    # === –≠–¢–ê–ü 3.2: –ö–æ—Ä—Ä–µ–ª—è—Ü–∏—è –º–µ–∂–¥—É –±–∏–Ω–∞—Ä–Ω—ã–º–∏ –º–µ—Ç–∫–∞–º–∏ ===
    plt.figure(figsize=(6, 5))
    corr = df[binary_targets].corr()
    sns.heatmap(corr, annot=True, cmap="coolwarm", fmt=".2f", square=True)
    plt.title("–ö–æ—Ä—Ä–µ–ª—è—Ü–∏–∏ –º–µ–∂–¥—É –±–∏–Ω–∞—Ä–Ω—ã–º–∏ –º–µ—Ç–∫–∞–º–∏")
    plt.tight_layout()
    plt.savefig("plots/eda_gen/classification_targets/analysis/binary_targets_corr_heatmap.png")
    plt.close()

    # === –≠–¢–ê–ü 3.3: Violinplot –ø–æ MolLogP / SI_gt_8 ===
    if "MolLogP" in df.columns:
        plt.figure(figsize=(6, 4))
        sns.violinplot(x="SI_gt_8", y="MolLogP", data=df, palette="Set2")
        plt.title("–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ MolLogP –ø–æ –∫–ª–∞—Å—Å–∞–º SI_gt_8")
        plt.tight_layout()
        plt.savefig("plots/eda_gen/classification_targets/analysis/MolLogP_by_SI_gt_8.png")
        plt.close()

    # === –≠–¢–ê–ü 3.4: DummyClassifier sanity-check ===
    for target in binary_targets:
        print(f"\nüìå DummyClassifier: {target}")

        # –ó–∞—â–∏—Ç–∞ –æ—Ç —É—Ç–µ—á–µ–∫
        forbidden_cols = binary_targets + [
            "IC50_nM", "CC50_nM", "SI_corrected",
            "log1p_IC50_nM", "log1p_CC50_nM", "log1p_SI"
        ]
        X = df.drop(columns=forbidden_cols, errors="ignore").select_dtypes(include="number")
        y = df[target]

        # Stratified split
        stratify_y = y if y.nunique() >= 2 and y.value_counts().min() >= 2 else None
        X_train, X_test, y_train, y_test = train_test_split(
            X, y, test_size=0.2, random_state=42, stratify=stratify_y
        )

        # Dummy model
        model = DummyClassifier(strategy="most_frequent")
        model.fit(X_train, y_train)
        y_pred = model.predict(X_test)

        # === –û—Ç—á–µ—Ç ===
        print(classification_report(y_test, y_pred, zero_division=0))

        # === –ú–∞—Ç—Ä–∏—Ü–∞ –æ—à–∏–±–æ–∫ ===
        cm = confusion_matrix(y_test, y_pred, labels=[0, 1])
        disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=["0", "1"])
        disp.plot(cmap="Blues", values_format="d")
        plt.title(f"DummyClassifier ‚Äî {target}")
        plt.tight_layout()
        plt.savefig(f"plots/eda_gen/classification_targets/dummy_reports/{target}_conf_matrix.png")
        plt.close()





    # === –≠–¢–ê–ü 4: Feature Engineering –∏ —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏—è –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ ===

    print("\n=== –≠–¢–ê–ü 4: Feature Engineering –∏ —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏—è –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ ===")


    # === –¶–µ–ª–µ–≤—ã–µ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ (–Ω–µ –ø—Ä–∏–∑–Ω–∞–∫–∏) ===
    target_cols = [
        "log1p_IC50_nM", "log1p_CC50_nM", "log1p_SI",
        "IC50_gt_median", "CC50_gt_median", "SI_gt_median", "SI_gt_8"
    ]

    # === Feature Engineering ===
    print("\nüìå –î–æ–±–∞–≤–ª—è–µ–º –Ω–æ–≤—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏:")
    if "MaxEStateIndex" in df.columns and "MinEStateIndex" in df.columns:
        df["EState_Delta"] = df["MaxEStateIndex"] - df["MinEStateIndex"]
        print("‚úÖ EState_Delta")
    if "NumHAcceptors" in df.columns and "NumHDonors" in df.columns:
        df["HAcceptors_to_HDonors_Ratio"] = df["NumHAcceptors"] / (df["NumHDonors"] + 1e-6)
        print("‚úÖ HAcceptors_to_HDonors_Ratio")
    if "MolLogP" in df.columns:
        df["MolLogP_sq"] = df["MolLogP"] ** 2
        print("‚úÖ MolLogP_sq")
    if "MolWt" in df.columns and "TPSA" in df.columns:
        df["MolWt_x_TPSA"] = df["MolWt"] * df["TPSA"]
        print("‚úÖ MolWt_x_TPSA")

    # === –ü—Ä–µ–¥–≤–∞—Ä–∏—Ç–µ–ª—å–Ω—ã–π –æ—Ç–±–æ—Ä —á–∏—Å–ª–æ–≤—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ ===
    X = df.select_dtypes(include=[np.number]).drop(columns=target_cols, errors="ignore")
    print(f"\nüî¢ –ß–∏—Å–ª–æ–≤—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –¥–æ —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏: {X.shape[1]}")

    # === –£–¥–∞–ª–µ–Ω–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ —Å >30% NaN ===
    nan_ratio = X.isna().mean()
    nan_features = nan_ratio[nan_ratio > 0.3].index.tolist()
    print(f"‚ö†Ô∏è –ü—Ä–∏–∑–Ω–∞–∫–æ–≤ —Å >30% NaN: {len(nan_features)}")

    # === –ö–æ–Ω—Å—Ç–∞–Ω—Ç–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏ ===
    constant_features = X.columns[X.nunique(dropna=False) <= 1].tolist()
    print(f"‚ùå –ö–æ–Ω—Å—Ç–∞–Ω—Ç–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏: {len(constant_features)}")

    # === –ù–∏–∑–∫–æ–≤–∞—Ä–∏–∞—Ç–∏–≤–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏ (std < 0.01) ===
    low_variance_features = X.columns[X.std() < 0.01].tolist()
    print(f"‚ö†Ô∏è –ù–∏–∑–∫–æ–≤–∞—Ä–∏–∞—Ç–∏–≤–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏ (< 0.01): {len(low_variance_features)}")

    # === –§–∏–Ω–∞–ª—å–Ω—ã–π —Å–ø–∏—Å–æ–∫ –∫ —É–¥–∞–ª–µ–Ω–∏—é ===
    bad_features = sorted(set(nan_features + constant_features + low_variance_features))
    print(f"üßπ –£–¥–∞–ª—è–µ—Ç—Å—è –≤—Å–µ–≥–æ: {len(bad_features)} –ø—Ä–∏–∑–Ω–∞–∫–æ–≤")

    with open("data/eda_gen/features/features_to_remove_preliminary.txt", "w") as f:
        for feat in bad_features:
            f.write(f"{feat}\n")

    # === –£–¥–∞–ª—è–µ–º –ø—Ä–∏–∑–Ω–∞–∫–∏ –∏–∑ –¥–∞—Ç–∞—Ñ—Ä–µ–π–º–∞ ===
    df = df.drop(columns=bad_features, errors="ignore")
    print(f"‚úÖ –ü–æ—Å–ª–µ —É–¥–∞–ª–µ–Ω–∏—è: {df.shape[1]} –∫–æ–ª–æ–Ω–æ–∫")

    # === –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è std —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–π ===
    plt.figure(figsize=(10, 4))
    X_std = df.select_dtypes(include=[np.number]).drop(columns=target_cols, errors="ignore").std()
    sns.histplot(X_std, bins=30, kde=True)
    plt.axvline(0.01, color='red', linestyle='--', label='–ü–æ—Ä–æ–≥ 0.01')
    plt.title("–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–æ–≥–æ –æ—Ç–∫–ª–æ–Ω–µ–Ω–∏—è –ø—Ä–∏–∑–Ω–∞–∫–æ–≤")
    plt.xlabel("Std")
    plt.ylabel("–ß–∞—Å—Ç–æ—Ç–∞")
    plt.legend()
    plt.tight_layout()
    plt.savefig("plots/eda_gen/features/std_distribution.png")
    plt.close()

    # === Heatmap –ø—Ä–æ–ø—É—Å–∫–æ–≤ ===
    plt.figure(figsize=(12, 5))
    sns.heatmap(df.isnull(), cbar=False)
    plt.title("–ö–∞—Ä—Ç–∞ –ø—Ä–æ–ø—É—â–µ–Ω–Ω—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π")
    plt.tight_layout()
    plt.savefig("plots/eda_gen/features/missing_heatmap.png")
    plt.close()

    # === –ò–º–ø—É—Ç–∞—Ü–∏—è NaN —Å—Ä–µ–¥–Ω–∏–º ===
    num_cols = df.select_dtypes(include=[np.number]).columns.tolist()
    if df[num_cols].isnull().any().any():
        imputer = SimpleImputer(strategy="median")
        df[num_cols] = imputer.fit_transform(df[num_cols])
        print("‚úÖ –ü—Ä–æ–ø—É—â–µ–Ω–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è —á–∏—Å–ª–æ–≤—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –∑–∞–ø–æ–ª–Ω–µ–Ω—ã –º–µ–¥–∏–∞–Ω–æ–π.")
    else:
        print("‚úÖ –ü—Ä–æ–ø—É—â–µ–Ω–Ω—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π –≤ —á–∏—Å–ª–æ–≤—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–∞—Ö –Ω–µ—Ç.")

    # === –°–æ—Ö—Ä–∞–Ω—è–µ–º –æ—á–∏—â–µ–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ ===
    df.to_csv("data/eda_gen/data_clean_pruned.csv", index=False)
    print("üíæ –°–æ—Ö—Ä–∞–Ω–µ–Ω–æ: data/eda_gen/data_clean_pruned.csv")

    # === –§–∏–Ω–∞–ª—å–Ω—ã–π —Å–ø–∏—Å–æ–∫ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ ===
    remaining_features = df.drop(columns=target_cols, errors='ignore').select_dtypes(include='number').columns.tolist()
    print(f"üîé –ü—Ä–∏–∑–Ω–∞–∫–æ–≤ –ø–æ—Å–ª–µ —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏: {len(remaining_features)}")

    # –ü—Ä–æ–≤–µ—Ä–∫–∞ —É–¥–∞–ª—ë–Ω–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
    print("\nüßæ –ü—Ä–æ–≤–µ—Ä–∫–∞ —É–¥–∞–ª—ë–Ω–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤:")
    with open("data/eda_gen/features/features_to_remove_preliminary.txt") as f:
        bad_features = [line.strip() for line in f]
    print(f"–£–¥–∞–ª–µ–Ω–æ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤: {len(bad_features)}")
    for col in bad_features[:10]:
        print(f"  ‚Ä¢ {col}")










    # === –≠–¢–ê–ü 5: –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–π –æ—Ç–±–æ—Ä –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –ø–æ MI —Å –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–µ–π ===
    print("\n=== –≠–¢–ê–ü 5: –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–π –æ—Ç–±–æ—Ä –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –ø–æ MI —Å –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–µ–π ===")



    # === –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö ===
    df = pd.read_csv("data/eda_gen/data_clean_pruned.csv")

    # === –°–ª–æ–≤–∞—Ä–∏ –∑–∞–¥–∞—á ===
    tasks = {
        "reg_log1p_IC50_nM": df["log1p_IC50_nM"],
        "reg_log1p_CC50_nM": df["log1p_CC50_nM"],
        "reg_log1p_SI": df["log1p_SI"],
        "clf_IC50_gt_median": df["IC50_gt_median"],
        "clf_CC50_gt_median": df["CC50_gt_median"],
        "clf_SI_gt_median": df["SI_gt_median"],
        "clf_SI_gt_8": df["SI_gt_8"]
    }

    forbidden_cols = [
        "log1p_IC50_nM", "log1p_CC50_nM", "log1p_SI",
        "IC50_gt_median", "CC50_gt_median", "SI_gt_median", "SI_gt_8",
        "IC50_nM", "CC50_nM", "SI_corrected"
    ]

    # === –ü—Ä–∏–∑–Ω–∞–∫–∏ –±–µ–∑ —Ç–∞—Ä–≥–µ—Ç–æ–≤ ===
    X = df.drop(columns=forbidden_cols, errors="ignore")
    print(f"‚úÖ –ß–∏—Å–ª–æ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –¥–ª—è MI: {X.shape[1]}")

    # === –†–∞—Å—á—ë—Ç MI –ø–æ –≤—Å–µ–º –∑–∞–¥–∞—á–∞–º ===
    mi_all = {}
    for task_name, y in tasks.items():
        is_clf = task_name.startswith("clf_")
        mi = mutual_info_classif(X, y, random_state=42) if is_clf else mutual_info_regression(X, y, random_state=42)

        mi_series = pd.Series(mi, index=X.columns).sort_values(ascending=False)
        mi_all[task_name] = mi_series

        cumulative_mi = mi_series.cumsum() / mi_series.sum()
        optimal_k = (cumulative_mi < 0.95).sum() + 1
        top_features = mi_series.head(optimal_k)

        # üíæ –°–æ—Ö—Ä–∞–Ω—è–µ–º
        top_features.to_csv(f"data/eda_gen/features/topMI_{task_name}.csv", header=["mutual_info"])
        with open(f"data/eda_gen/features/{task_name}.txt", "w") as f:
            f.writelines([f"{feat}\n" for feat in top_features.index])

        # üìä Top-25 Barplot
        plt.figure(figsize=(10, 6))
        sns.barplot(x=top_features.head(25).values, y=top_features.head(25).index, palette="viridis")
        plt.title(f"Top-25 MI –¥–ª—è: {task_name}")
        plt.xlabel("Mutual Information")
        plt.ylabel("–ü—Ä–∏–∑–Ω–∞–∫–∏")
        plt.tight_layout()
        plt.savefig(f"plots/eda_gen/feature_importance/top25_{task_name}.png")
        plt.close()

        # üìà –ö—É–º—É–ª—è—Ç–∏–≤–Ω—ã–π –≥—Ä–∞—Ñ–∏–∫
        plt.figure(figsize=(8, 5))
        plt.plot(range(1, len(cumulative_mi)+1), cumulative_mi.values, marker='o')
        plt.axhline(0.95, color='r', linestyle='--', label='95% –ø–æ—Ä–æ–≥')
        plt.axvline(optimal_k, color='g', linestyle='--', label=f"K = {optimal_k}")
        plt.title(f"–ö—É–º—É–ª—è—Ç–∏–≤–Ω–∞—è –≤–∞–∂–Ω–æ—Å—Ç—å MI –¥–ª—è: {task_name}")
        plt.xlabel("–ß–∏—Å–ª–æ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤")
        plt.ylabel("–ö—É–º—É–ª—è—Ç–∏–≤–Ω–∞—è –¥–æ–ª—è MI")
        plt.grid(True)
        plt.legend()
        plt.tight_layout()
        plt.savefig(f"plots/eda_gen/feature_importance/cumulative_MI_{task_name}.png")
        plt.close()

        print(f"üìå {task_name}: –≤—ã–±—Ä–∞–Ω–æ {optimal_k} –ø—Ä–∏–∑–Ω–∞–∫–æ–≤. ‚úÖ")

    # === –°–≤–æ–¥–∫–∞ –ø–æ –∫–æ–ª–∏—á–µ—Å—Ç–≤—É –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ ===
    print("\n=== –°–≤–æ–¥–∫–∞ –ø–æ –∫–æ–ª–∏—á–µ—Å—Ç–≤—É –æ—Ç–æ–±—Ä–∞–Ω–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ ===")
    for task_name, mi_series in mi_all.items():
        k = (mi_series.cumsum() / mi_series.sum() < 0.95).sum() + 1
        print(f"{task_name}: {k} –ø—Ä–∏–∑–Ω–∞–∫–æ–≤")

    # === –ü–µ—á–∞—Ç—å top-25 –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ ===
    print("\n=== –¢–û–ü-25 –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –ø–æ MI –¥–ª—è –∫–∞–∂–¥–æ–π –∑–∞–¥–∞—á–∏ ===")
    for task_name, mi_series in mi_all.items():
        print(f"\nüìå {task_name} ‚Äî top 25 –ø—Ä–∏–∑–Ω–∞–∫–æ–≤:")
        for i, (feat, score) in enumerate(mi_series.head(25).items(), 1):
            print(f"{i:2d}. {feat:<30} ‚Üí MI = {score:.4f}")

    # === –û–±—â–∏–π —Ä–µ–π—Ç–∏–Ω–≥ –ø–æ —Å—Ä–µ–¥–Ω–µ–π MI ===
    mi_df = pd.DataFrame(mi_all)

    for col in forbidden_cols:
        assert col not in mi_df.index, f"üö® –£—Ç–µ—á–∫–∞! –ü—Ä–∏–∑–Ω–∞–∫ {col} –ø–æ–ø–∞–ª –≤ –∏—Ç–æ–≥–æ–≤—É—é —Ç–∞–±–ª–∏—Ü—É MI."

    mi_df["MI_avg"] = mi_df.mean(axis=1)
    mi_ranked = mi_df.sort_values("MI_avg", ascending=False)

    mi_ranked.to_csv("data/eda_gen/features/mi_rank_all_tasks.csv")
    print("üìÅ –°–æ—Ö—Ä–∞–Ω—ë–Ω –æ–±—â–∏–π —Ä–µ–π—Ç–∏–Ω–≥ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤: data/eda_gen/features/mi_rank_all_tasks.csv")

    # === –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è —Ç–æ–ø-20 –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ ===
    top_features = mi_ranked["MI_avg"].head(20)

    plt.figure(figsize=(10, 6))
    sns.barplot(x=top_features.values, y=top_features.index, palette="mako")
    plt.title("Top-20 –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –ø–æ —Å—Ä–µ–¥–Ω–µ–π –≤–∑–∞–∏–º–Ω–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ (–≤—Å–µ –∑–∞–¥–∞—á–∏)")
    plt.xlabel("–°—Ä–µ–¥–Ω—è—è Mutual Information")
    plt.ylabel("–ü—Ä–∏–∑–Ω–∞–∫–∏")
    plt.tight_layout()
    plt.savefig("plots/eda_gen/feature_importance/overall_MI_ranking.png")
    plt.close()






    print("\n=== –≠–¢–ê–ü 6: –§–∏–Ω–∞–ª—å–Ω–æ–µ —É–¥–∞–ª–µ–Ω–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –ø–æ –≤—ã—Å–æ–∫–æ–π –∫–æ—Ä—Ä–µ–ª—è—Ü–∏–∏ (r > 0.95) —Å –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç–æ–º MI ===")

    # === –≠–¢–ê–ü 6: –§–∏–Ω–∞–ª—å–Ω–æ–µ —É–¥–∞–ª–µ–Ω–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –ø–æ –≤—ã—Å–æ–∫–æ–π –∫–æ—Ä—Ä–µ–ª—è—Ü–∏–∏ (r > 0.95) —Å –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç–æ–º MI ===


    # === –ö–æ–Ω—Å—Ç–∞–Ω—Ç—ã ===
    DATA_PATH = "data/eda_gen/data_clean_pruned.csv"
    FINAL_PATH = "data/eda_gen/data_final.csv"
    FEATURES_DIR = "data/eda_gen/features"
    PLOTS_DIR = "plots/eda_gen/feature_importance"

    # === –ó–∞–≥—Ä—É–∑–∫–∞ ===
    df = pd.read_csv(DATA_PATH)
    drop_cols = [
        "IC50_nM", "CC50_nM", "SI_corrected",
        "log1p_IC50_nM", "log1p_CC50_nM", "log1p_SI",
        "IC50_gt_median", "CC50_gt_median", "SI_gt_median", "SI_gt_8"
    ]
    X = df.drop(columns=drop_cols, errors="ignore")
    print(f"üî¢ –ü—Ä–∏–∑–Ω–∞–∫–æ–≤ –¥–æ —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏: {X.shape[1]}")

    # === –†–∞—Å—á—ë—Ç MI –ø–æ –≤—Å–µ–º –∑–∞–¥–∞—á–∞–º ===
    mi_df = pd.DataFrame(index=X.columns)
    mi_df["reg_IC50"] = mutual_info_regression(X, df["log1p_IC50_nM"], random_state=42)
    mi_df["reg_CC50"] = mutual_info_regression(X, df["log1p_CC50_nM"], random_state=42)
    mi_df["reg_SI"] = mutual_info_regression(X, df["log1p_SI"], random_state=42)
    mi_df["clf_IC50"] = mutual_info_classif(X, df["IC50_gt_median"], random_state=42)
    mi_df["clf_CC50"] = mutual_info_classif(X, df["CC50_gt_median"], random_state=42)
    mi_df["clf_SI"] = mutual_info_classif(X, df["SI_gt_median"], random_state=42)
    mi_df["clf_SI_gt_8"] = mutual_info_classif(X, df["SI_gt_8"], random_state=42)
    mi_df["MI_avg"] = mi_df.mean(axis=1)
    mi_df.to_csv(f"{FEATURES_DIR}/mi_reg_avg.csv")
    print("‚úÖ MI —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞: mi_reg_avg.csv")

    # === –ú–∞—Ç—Ä–∏—Ü–∞ –∫–æ—Ä—Ä–µ–ª—è—Ü–∏–π ===
    corr_matrix = X.corr().abs()
    upper_tri = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(bool))

    plt.figure(figsize=(14, 12))
    sns.heatmap(corr_matrix, cmap="coolwarm", square=True, linewidths=0.5)
    plt.title("–ú–∞—Ç—Ä–∏—Ü–∞ –∫–æ—Ä—Ä–µ–ª—è—Ü–∏–π (–¥–æ —É–¥–∞–ª–µ–Ω–∏—è)")
    plt.tight_layout()
    plt.savefig(f"{PLOTS_DIR}/correlation_matrix.png")
    plt.close()

    # === –£–¥–∞–ª–µ–Ω–∏–µ –≤—ã—Å–æ–∫–æ –∫–æ—Ä—Ä–µ–ª–∏—Ä—É—é—â–∏—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ —Å –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç–æ–º –ø–æ MI ===
    high_corr_pairs = [
        (col, row, upper_tri.loc[row, col])
        for col in upper_tri.columns
        for row in upper_tri.index
        if pd.notnull(upper_tri.loc[row, col]) and upper_tri.loc[row, col] > 0.95
    ]
    print(f"üîó –ù–∞–π–¥–µ–Ω–æ –ø–∞—Ä —Å r > 0.95: {len(high_corr_pairs)}")

    features_to_drop_final = set()
    for a, b, r in high_corr_pairs:
        if a in features_to_drop_final or b in features_to_drop_final:
            continue
        if mi_df.loc[a, "MI_avg"] >= mi_df.loc[b, "MI_avg"]:
            features_to_drop_final.add(b)
        else:
            features_to_drop_final.add(a)
    print(f"üóëÔ∏è –£–¥–∞–ª—è–µ–º: {len(features_to_drop_final)} –ø—Ä–∏–∑–Ω–∞–∫–æ–≤")

    with open(f"{FEATURES_DIR}/high_corr_removed_by_MI.txt", "w") as f:
        for feat in sorted(features_to_drop_final):
            f.write(f"{feat}\n")

    # === –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ –¥–∞—Ç–∞—Å–µ—Ç–∞ ===
    df_final = df.drop(columns=features_to_drop_final, errors="ignore")
    df_final.to_csv(FINAL_PATH, index=False)
    print(f"üíæ –°–æ—Ö—Ä–∞–Ω–µ–Ω–æ: {FINAL_PATH} ({df_final.shape[1]} –ø—Ä–∏–∑–Ω–∞–∫–æ–≤)")

    # === –°–ø–∏—Å–æ–∫ —É–¥–∞–ª—ë–Ω–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ —Å –æ–±–æ—Å–Ω–æ–≤–∞–Ω–∏–µ–º ===
    deleted_info = []
    for a, b, r in high_corr_pairs:
        if a in features_to_drop_final:
            kept, dropped = b, a
        elif b in features_to_drop_final:
            kept, dropped = a, b
        else:
            continue
        deleted_info.append({
            "dropped_feature": dropped,
            "kept_feature": kept,
            "correlation": r,
            "MI_dropped": mi_df.loc[dropped, "MI_avg"],
            "MI_kept": mi_df.loc[kept, "MI_avg"],
            "reason": f"r = {r:.3f}, {dropped} < {kept} –ø–æ MI"
        })
    deleted_df = pd.DataFrame(deleted_info)
    deleted_df.to_csv(f"{FEATURES_DIR}/deleted_features_with_reasons.csv", index=False)

    # === –§–∏–Ω–∞–ª—å–Ω–∞—è –∫–æ—Ä—Ä–µ–ª—è—Ü–∏–æ–Ω–Ω–∞—è –º–∞—Ç—Ä–∏—Ü–∞ ===
    corr_matrix_final = df_final.drop(columns=drop_cols, errors="ignore").corr().abs()
    plt.figure(figsize=(14, 12))
    sns.heatmap(corr_matrix_final, cmap="coolwarm", square=True, linewidths=0.5)
    plt.title("–ú–∞—Ç—Ä–∏—Ü–∞ –∫–æ—Ä—Ä–µ–ª—è—Ü–∏–π (–ø–æ—Å–ª–µ —É–¥–∞–ª–µ–Ω–∏—è)")
    plt.tight_layout()
    plt.savefig(f"{PLOTS_DIR}/correlation_matrix_after.png")
    plt.close()

    # === –ü–µ—á–∞—Ç—å –≤—Å–µ—Ö —É–¥–∞–ª—ë–Ω–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ ===
    print("\nüìã –£–¥–∞–ª—ë–Ω–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏ –ø–æ MI –ø—Ä–∏ r > 0.95:")
    for feat in sorted(features_to_drop_final):
        print(f"‚Ä¢ {feat}")






    # === –≠–¢–ê–ü 7: –ú–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ ===

    # === –ó–∞–≥—Ä—É–∑–∫–∞ ===
    df = pd.read_csv("data/eda_gen/data_final.csv")

    # === –¶–µ–ª–µ–≤—ã–µ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ (–Ω–µ –º–∞—Å—à—Ç–∞–±–∏—Ä—É–µ–º) ===
    target_cols = [
        "log1p_IC50_nM", "log1p_CC50_nM", "log1p_SI",
        "IC50_gt_median", "CC50_gt_median", "SI_gt_median", "SI_gt_8"
    ]

    # === –¢–æ–ª—å–∫–æ –ø—Ä–∏–∑–Ω–∞–∫–∏ ===
    X = df.drop(columns=target_cols, errors="ignore")
    X_numeric = X.select_dtypes(include=[np.number])

    # === –†–∞–∑–¥–µ–ª–µ–Ω–∏–µ –Ω–∞ –±–∏–Ω–∞—Ä–Ω—ã–µ –∏ –Ω–µ–ø—Ä–µ—Ä—ã–≤–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏ ===
    binary_features = [col for col in X_numeric.columns if set(df[col].dropna().unique()).issubset({0, 1})]
    continuous_features = [col for col in X_numeric.columns if col not in binary_features]

    print(f"üî¢ –í—Å–µ–≥–æ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤: {X_numeric.shape[1]}")
    print(f"‚úÖ –ë–∏–Ω–∞—Ä–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤: {len(binary_features)}")
    print(f"üîß –ú–∞—Å—à—Ç–∞–±–∏—Ä—É–µ–º –Ω–µ–ø—Ä–µ—Ä—ã–≤–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏: {len(continuous_features)}")

    # === –ú–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω–∏–µ ===
    scaler = StandardScaler()
    X_scaled = X_numeric.copy()
    X_scaled[continuous_features] = scaler.fit_transform(X_scaled[continuous_features])

    # === –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ ===
    X_scaled.to_csv("data/eda_gen/scaled/X_scaled.csv", index=False)

    df_scaled = pd.concat([X_scaled, df[target_cols]], axis=1)
    df_scaled.to_csv("data/eda_gen/scaled/data_scaled.csv", index=False)

    joblib.dump(scaler, "data/eda_gen/scaled/scaler_reg.pkl")

    print("üìÅ –°–æ—Ö—Ä–∞–Ω–µ–Ω–æ:")
    print("‚Üí data/eda_gen/scaled/X_scaled.csv")
    print("‚Üí data/eda_gen/scaled/data_scaled.csv")
    print("‚Üí data/eda_gen/scaled/scaler_reg.pkl")


    desc = X_scaled.describe().T
    suspects = desc[desc["max"] > 500].index.tolist()
    print(f"‚ö†Ô∏è –ü–æ–¥–æ–∑—Ä–∏—Ç–µ–ª—å–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏ –ø–æ max > 500: {suspects}")







    # === –≠–¢–ê–ü 8: –ü—Ä–æ–µ–∫—Ü–∏–∏ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ (PCA, UMAP, LDA) –ø–æ –∑–∞–¥–∞—á–∞–º ===


    # === üì¶ –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö ===
    X_scaled = pd.read_csv("data/eda_gen/scaled/X_scaled.csv")
    df = pd.read_csv("data/eda_gen/data_final.csv")

    # === üß≠ –ó–∞–¥–∞—á–∏ –∏ —Ç–∞—Ä–≥–µ—Ç—ã ===
    tasks = {
        "reg_log1p_IC50_nM": "log1p_IC50_nM",
        "reg_log1p_CC50_nM": "log1p_CC50_nM",
        "reg_log1p_SI": "log1p_SI",
        "clf_IC50_gt_median": "IC50_gt_median",
        "clf_CC50_gt_median": "CC50_gt_median",
        "clf_SI_gt_median": "SI_gt_median",
        "clf_SI_gt_8": "SI_gt_8"
    }

    # === –ì–ª–æ–±–∞–ª—å–Ω–∞—è PCA –Ω–∞ –≤—Å–µ—Ö –ø—Ä–∏–∑–Ω–∞–∫–∞—Ö ===
    pca_all = PCA(n_components=100, random_state=42)
    X_pca_all = pca_all.fit_transform(X_scaled)
    explained_var = pca_all.explained_variance_ratio_
    cumulative_var = np.cumsum(explained_var)

    plt.figure(figsize=(10, 6))
    plt.plot(range(1, len(explained_var)+1), explained_var, marker='o', label="–û–±—ä—è—Å–Ω—ë–Ω–Ω–∞—è –¥–∏—Å–ø–µ—Ä—Å–∏—è")
    plt.plot(range(1, len(cumulative_var)+1), cumulative_var, marker='s', label="–ù–∞–∫–æ–ø–ª–µ–Ω–Ω–∞—è –¥–∏—Å–ø–µ—Ä—Å–∏—è")
    plt.axhline(0.95, color='red', linestyle='--', label="95% –¥–∏—Å–ø–µ—Ä—Å–∏–∏")
    plt.xlabel("–ö–æ–º–ø–æ–Ω–µ–Ω—Ç–∞")
    plt.ylabel("–î–æ–ª—è –¥–∏—Å–ø–µ—Ä—Å–∏–∏")
    plt.title("PCA: –æ–±—ä—è—Å–Ω—ë–Ω–Ω–∞—è –∏ –Ω–∞–∫–æ–ø–ª–µ–Ω–Ω–∞—è –¥–∏—Å–ø–µ—Ä—Å–∏—è")
    plt.grid(True)
    plt.legend()
    plt.tight_layout()
    plt.savefig("plots/eda_gen/projections_variance/pca_explained_variance.png")
    plt.close()

    # === –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –ø—Ä–æ–µ–∫—Ü–∏–π –ø–æ –∑–∞–¥–∞—á–∞–º ===
    for task, target_col in tasks.items():
        feat_path = f"data/eda_gen/features/{task}.txt"
        if not os.path.exists(feat_path):
            print(f"‚ùå –ù–µ—Ç –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –¥–ª—è {task}")
            continue

        with open(feat_path) as f:
            features = [line.strip() for line in f if line.strip() in X_scaled.columns]

        if len(features) < 2:
            print(f"‚ö†Ô∏è –ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –¥–ª—è {task}")
            continue

        X_task = X_scaled[features]
        y = df[target_col]
        is_clf = task.startswith("clf_")

        # === PCA ===
        pca = PCA(n_components=2, random_state=42)
        X_pca = pca.fit_transform(X_task)
        cmap = "tab10" if is_clf else "viridis"
        plt.figure(figsize=(8, 6))
        plt.scatter(X_pca[:, 0], X_pca[:, 1], c=y, cmap=cmap, alpha=0.7)
        plt.colorbar()
        plt.title(f"PCA: {task}")
        plt.xlabel("PC1")
        plt.ylabel("PC2")
        plt.tight_layout()
        plt.savefig(f"plots/eda_gen/projections_task/pca/{task}.png")
        plt.close()

        # === UMAP ===
        reducer = umap.UMAP(n_components=2, random_state=42)
        X_umap = reducer.fit_transform(X_task)
        cmap = "tab10" if is_clf else "plasma"
        plt.figure(figsize=(8, 6))
        plt.scatter(X_umap[:, 0], X_umap[:, 1], c=y, cmap=cmap, alpha=0.7)
        plt.colorbar()
        plt.title(f"UMAP: {task}")
        plt.xlabel("UMAP1")
        plt.ylabel("UMAP2")
        plt.tight_layout()
        plt.savefig(f"plots/eda_gen/projections_task/umap/{task}.png")
        plt.close()

        # === LDA (—Ç–æ–ª—å–∫–æ –¥–ª—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏) ===
        if is_clf:
            y_array = y.values
            n_classes = len(np.unique(y_array))
            max_components = min(len(features), n_classes - 1)
            if max_components < 1:
                continue
            lda = LinearDiscriminantAnalysis(n_components=max_components)
            X_lda = lda.fit_transform(X_task, y_array)
            plt.figure(figsize=(8, 6))
            if max_components == 1:
                plt.scatter(X_lda[:, 0], [0]*len(X_lda), c=y_array, cmap="coolwarm", alpha=0.7)
                plt.yticks([])
            else:
                plt.scatter(X_lda[:, 0], X_lda[:, 1], c=y_array, cmap="coolwarm", alpha=0.7)
                plt.ylabel("LDA2")
            plt.xlabel("LDA1")
            plt.title(f"LDA: {task}")
            plt.colorbar()
            plt.tight_layout()
            plt.savefig(f"plots/eda_gen/projections_task/lda/{task}.png")
            plt.close()






    # === –≠–¢–ê–ü 9: –ó–∞–≤–µ—Ä—à–µ–Ω–∏–µ EDA –∏ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ –∞—Ä—Ç–µ—Ñ–∞–∫—Ç–æ–≤ ===

    print("\n=== –≠–¢–ê–ü 9: –ó–∞–≤–µ—Ä—à–µ–Ω–∏–µ –ø–∞–π–ø–ª–∞–π–Ω–∞ EDA ===")

    # === –ó–∞–≥—Ä—É–∂–∞–µ–º —Ñ–∏–Ω–∞–ª—å–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ ===
    df_final = pd.read_csv("data/eda_gen/data_final.csv")
    X_scaled = pd.read_csv("data/eda_gen/scaled/X_scaled.csv")

    # === –ü—Ä–æ–≤–µ—Ä–∫–∞ —Ñ–∏–Ω–∞–ª—å–Ω—ã—Ö —Ä–∞–∑–º–µ—Ä–æ–≤ ===
    print(f"‚úÖ –§–∏–Ω–∞–ª—å–Ω—ã–π –¥–∞—Ç–∞—Ñ—Ä–µ–π–º: {df_final.shape[0]} —Å—Ç—Ä–æ–∫, {df_final.shape[1]} –∫–æ–ª–æ–Ω–æ–∫")
    print(f"‚úÖ –ú–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏: {X_scaled.shape[0]} —Å—Ç—Ä–æ–∫, {X_scaled.shape[1]} –ø—Ä–∏–∑–Ω–∞–∫–æ–≤")

    # === –°–ø–∏—Å–æ–∫ —Ñ–∏–Ω–∞–ª—å–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ ===
    final_features = X_scaled.columns.tolist()
    with open("data/eda_gen/features/final_feature_list.txt", "w") as f:
        for feat in final_features:
            f.write(f"{feat}\n")
    print("üìù –§–∏–Ω–∞–ª—å–Ω—ã–π —Å–ø–∏—Å–æ–∫ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ —Å–æ—Ö—Ä–∞–Ω—ë–Ω: data/eda_gen/features/final_feature_list.txt")

    # === –õ–æ–≥ —Ñ–∏–Ω–∞–ª—å–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤ ===
    print("\nüì¶ –§–∏–Ω–∞–ª—å–Ω—ã–µ —Ñ–∞–π–ª—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã:")
    print(" ‚Ä¢ data/eda_gen/data_clean.csv ‚Äî –ø–æ—Å–ª–µ –ª–æ–≥–∞—Ä–∏—Ñ–º–∏—Ä–æ–≤–∞–Ω–∏—è –∏ outlier-–æ—á–∏—Å—Ç–∫–∏")
    print(" ‚Ä¢ data/eda_gen/data_clean_pruned.csv ‚Äî –ø–æ—Å–ª–µ Feature Engineering –∏ —É–¥–∞–ª–µ–Ω–∏—è –ø–ª–æ—Ö–∏—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤")
    print(" ‚Ä¢ data/eda_gen/data_final.csv ‚Äî –ø–æ—Å–ª–µ –∫–æ—Ä—Ä–µ–ª—è—Ü–∏–æ–Ω–Ω–æ–π —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏")
    print(" ‚Ä¢ data/eda_gen/scaled/X_scaled.csv ‚Äî –º–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏")
    print(" ‚Ä¢ data/eda_gen/features/final_feature_list.txt ‚Äî –æ—Ç–æ–±—Ä–∞–Ω–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏")

    print("\n‚úÖ –≠—Ç–∞–ø EDA –∑–∞–≤–µ—Ä—à—ë–Ω.")




if __name__ == "__main__":
    main()
