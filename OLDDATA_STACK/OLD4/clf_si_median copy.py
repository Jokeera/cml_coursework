print("clf_si_median - active")

# === –ò–º–ø–æ—Ä—Ç—ã ===
import os
import joblib
import shap
import logging
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt


from sklearn.metrics import precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix

import matplotlib.pyplot as plt
from sklearn.feature_selection import mutual_info_classif, SelectKBest
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.linear_model import LogisticRegression


from sklearn.feature_selection import SelectKBest, mutual_info_classif
from sklearn.model_selection import cross_val_score
import matplotlib.pyplot as plt


from sklearn.model_selection import (
    GridSearchCV, StratifiedKFold, cross_val_score, cross_val_predict
)
from sklearn.metrics import (
    classification_report, confusion_matrix, roc_auc_score,
    accuracy_score, precision_score, recall_score, f1_score, roc_curve
)
from sklearn.preprocessing import StandardScaler, RobustScaler
from sklearn.pipeline import Pipeline, make_pipeline
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import StackingClassifier
from sklearn.feature_selection import SelectFromModel

from catboost import CatBoostClassifier, Pool
from xgboost import XGBClassifier

from sklearn.preprocessing import StandardScaler, RobustScaler
from sklearn.model_selection import cross_val_score, StratifiedKFold
from sklearn.pipeline import make_pipeline
from catboost import CatBoostClassifier

# === –õ–æ–≥–≥–∏—Ä–æ–≤–∞–Ω–∏–µ ===
logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s - %(name)s - %(levelname)s - %(message)s"
)
logger = logging.getLogger(__name__)

def run_clf_si_median():



    # === –ö–æ–Ω—Å—Ç–∞–Ω—Ç—ã ===
    RANDOM_STATE = 42
    N_SPLITS_CV = 5
    N_TOP_FEATURES_TO_SELECT = 45
    TASK_NAME = "clf_si_median"
    DATA_FILE = "data/eda_gen/data_final.csv"
    FEATURE_FILE = "data/eda_gen/features/clf_SI_gt_median.txt"
    SCALE_METHODS = {"standard": StandardScaler(), "robust": RobustScaler()}
    PLOTS_DIR = f"plots/classification/{TASK_NAME}"
    MODELS_DIR = f"models/{TASK_NAME}"
    FEATURES_DIR = "features"

    os.makedirs(PLOTS_DIR, exist_ok=True)
    os.makedirs(MODELS_DIR, exist_ok=True)







    # === –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö ===
    df = pd.read_csv(DATA_FILE)
    X_all = df.copy()  # ‚úÖ –æ—Å—Ç–∞–≤–ª—è–µ–º –≤—Å–µ –∫–æ–ª–æ–Ω–∫–∏, –≤–∫–ª—é—á–∞—è –∫–∞—Ç–µ–≥–æ—Ä–∏–∞–ª—å–Ω—ã–µ

    # === –§–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–∏–µ —Ç–∞—Ä–≥–µ—Ç–∞ ===
    if "SI_corrected" not in df.columns:
        logger.error("–ö–æ–ª–æ–Ω–∫–∞ 'SI_corrected' –Ω–µ –Ω–∞–π–¥–µ–Ω–∞ –≤ –¥–∞–Ω–Ω—ã—Ö")
        exit()

    median_val = df["SI_corrected"].median()
    y = (df["SI_corrected"] > median_val).astype(int)
    y.name = "target"
    logger.info(f"–¶–µ–ª—å: SI_gt_median (–±–∏–Ω–∞—Ä–Ω—ã–π –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä), –ë–∞–ª–∞–Ω—Å –∫–ª–∞—Å—Å–æ–≤:\n{y.value_counts(normalize=True).rename('proportion')}")

    # === –£–¥–∞–ª–µ–Ω–∏–µ —Ü–µ–ª–µ–≤–æ–π –ø–µ—Ä–µ–º–µ–Ω–Ω–æ–π –∏ –ø–æ—Ç–µ–Ω—Ü–∏–∞–ª—å–Ω—ã—Ö —É—Ç–µ—á–µ–∫ ===
    forbidden_cols = [
        # CC50-related
        "CC50", "CC50_mM", "CC50_nM", "log_CC50", "log1p_CC50", "log1p_CC50_nM", "CC50_gt_median",

        # IC50-related
        "IC50", "IC50_mM", "IC50_nM", "log_IC50", "log1p_IC50", "log1p_IC50_nM", "IC50_gt_median",

        # SI-related
        "SI", "SI_corrected", "log_SI", "log1p_SI", "log1p_SI_corrected",
        "SI_original", "SI_diff", "SI_diff_check", "SI_check", "SI_gt_median", "SI_gt_8",

        # Other leakage-related
        "ratio_IC50_CC50", "Unnamed: 0"
    ]

    removed_cols = [col for col in forbidden_cols if col in df.columns]
    df = df.drop(columns=removed_cols)
    X_all = df.select_dtypes(include="number").copy()
    logger.info(f"‚úÖ –£–¥–∞–ª–µ–Ω—ã –ø–æ—Ç–µ–Ω—Ü–∏–∞–ª—å–Ω–æ —É—Ç–µ—á–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏: {removed_cols}")










    # === –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ª—É—á—à–µ–≥–æ —á–∏—Å–ª–∞ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ —Å –∫—Ä–æ—Å—Å-–≤–∞–ª–∏–¥–∞—Ü–∏–µ–π
    cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)

    max_k = 60
    roc_scores = []

    for k in range(10, max_k + 1, 10):
        selector = SelectKBest(score_func=mutual_info_classif, k=k)
        X_k = selector.fit_transform(X_all, y)
        pipe = make_pipeline(StandardScaler(), CatBoostClassifier(verbose=0, random_state=RANDOM_STATE))
        score = cross_val_score(pipe, X_k, y, cv=cv, scoring="roc_auc", n_jobs=-1).mean()
        roc_scores.append((k, score))
        print(f"k = {k}, ROC AUC = {score:.4f}")

    # –ì—Ä–∞—Ñ–∏–∫ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –∫–∞—á–µ—Å—Ç–≤–∞ –æ—Ç –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
    ks, scores = zip(*roc_scores)
    plt.figure(figsize=(8, 5))
    plt.plot(ks, scores, marker="o")
    plt.xlabel("–ß–∏—Å–ª–æ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ (k)")
    plt.ylabel("ROC AUC (CV)")
    plt.title("–ü–æ–¥–±–æ—Ä –æ–ø—Ç–∏–º–∞–ª—å–Ω–æ–≥–æ –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤")
    plt.grid(True)
    plt.tight_layout()
    plt.savefig(os.path.join(PLOTS_DIR, f"{TASK_NAME}_feature_selection_curve.png"))
    plt.close()








    # === –û—Ç–±–æ—Ä –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –ø–æ Mutual Information ===


    logger.info("–û—Ç–±–æ—Ä –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –ø–æ Mutual Information (MI)...")
    selector = SelectKBest(score_func=mutual_info_classif, k=45)
    selector.fit(X_all, y)
    X = selector.transform(X_all)
    selected_features = X_all.columns[selector.get_support()].tolist()

    logger.info(f"‚úÖ –û—Ç–æ–±—Ä–∞–Ω–æ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –ø–æ MI: {len(selected_features)} –∏–∑ {X_all.shape[1]}")
    X_df = pd.DataFrame(X, columns=selected_features)











    # === A/B —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –¥–≤—É—Ö —Å–∫–µ–π–ª–µ—Ä–æ–≤ ===
    logger.info("üîç A/B-—Ç–µ—Å—Ç —Å–∫–µ–π–ª–µ—Ä–æ–≤: StandardScaler vs RobustScaler...")

    cv = StratifiedKFold(n_splits=N_SPLITS_CV, shuffle=True, random_state=RANDOM_STATE)
    scalers = {
        "StandardScaler": StandardScaler(),
        "RobustScaler": RobustScaler()
    }

    best_scaler_name = None
    best_roc_auc = -np.inf
    best_scaler = None

    for name, scaler in scalers.items():
        pipe = make_pipeline(
            scaler,
            CatBoostClassifier(verbose=0, random_state=RANDOM_STATE)
        )
        roc_auc = cross_val_score(pipe, X, y, cv=cv, scoring="roc_auc", n_jobs=-1).mean()
        logger.info(f"ROC AUC ({name}): {roc_auc:.4f}")
        
        if roc_auc > best_roc_auc:
            best_roc_auc = roc_auc
            best_scaler_name = name
            best_scaler = scaler

    logger.info(f"‚úÖ –í—ã–±—Ä–∞–Ω –ª—É—á—à–∏–π —Å–∫–µ–π–ª–µ—Ä: {best_scaler_name} (ROC AUC = {best_roc_auc:.4f})")


    # === –•—Ä–∞–Ω–∏–ª–∏—â–µ –ª—É—á—à–∏—Ö –º–æ–¥–µ–ª–µ–π ===
    tuned_models = []

    # === –ü–æ–¥—Å—á—ë—Ç class_weights –≤—Ä—É—á–Ω—É—é –¥–ª—è CC50 ===
    class_counts = y.value_counts()
    total = len(y)
    class_weights = [
        total / (2 * class_counts[0]),  # –≤–µ—Å –¥–ª—è –∫–ª–∞—Å—Å–∞ 0
        total / (2 * class_counts[1])   # –≤–µ—Å –¥–ª—è –∫–ª–∞—Å—Å–∞ 1
    ]

    # === –°–ø–∏—Å–æ–∫ –º–æ–¥–µ–ª–µ–π —Å –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏ –¥–ª—è GridSearch ===
    models = {
        "catboost": {
            "model": CatBoostClassifier(
                verbose=0,
                random_state=RANDOM_STATE,
                class_weights=class_weights,
                l2_leaf_reg=10.0  # —Ä–µ–≥—É–ª—è—Ä–∏–∑–∞—Ü–∏—è –¥–ª—è –±–æ—Ä—å–±—ã —Å –ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∏–µ–º
            ),
        "params": {
            "iterations": [200],        # –º–µ–Ω—å—à–µ –¥–µ—Ä–µ–≤—å–µ–≤
            "learning_rate": [0.01],
            "depth": [4, 5]             # —É–º–µ—Ä–µ–Ω–Ω–∞—è –≥–ª—É–±–∏–Ω–∞
        }

        },
        "xgboost": {
            "model": XGBClassifier(
                eval_metric="logloss",
                random_state=RANDOM_STATE
            ),
        "params": {
            "n_estimators": [200, 400],
            "learning_rate": [0.01],
            "max_depth": [3, 5],
            "subsample": [0.7],
            "colsample_bytree": [1.0]
        }

        }
    }


    # === –¢—é–Ω–∏–Ω–≥ –±–∞–∑–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π ===
    for name, config in models.items():
        logger.info(f"–¢—é–Ω–∏–Ω–≥ –º–æ–¥–µ–ª–∏: {name}")
        pipe = Pipeline([
            ("scaler", best_scaler),  # –ò—Å–ø–æ–ª—å–∑—É–µ–º –ª—É—á—à–∏–π —Å–∫–µ–π–ª–µ—Ä
            ("classifier", config["model"])
        ])
        grid_search_params = {'classifier__' + k: v for k, v in config["params"].items()}
        gs = GridSearchCV(
            pipe,
            grid_search_params,
            cv=StratifiedKFold(n_splits=N_SPLITS_CV, shuffle=True, random_state=RANDOM_STATE),
            scoring="roc_auc",
            n_jobs=-1,
            verbose=1
        )
        # === –û–±—ë—Ä—Ç–∫–∞ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –≤ DataFrame —Å –ø—Ä–∞–≤–∏–ª—å–Ω—ã–º–∏ –∏–º–µ–Ω–∞–º–∏ ===
        X_df = pd.DataFrame(X, columns=selected_features)

        # === –û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏ —Å –ø–æ–¥–±–æ—Ä–æ–º –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ ===
        gs.fit(X_df, y)
        logger.info(f"Best ROC AUC {name}: {gs.best_score_:.4f}, –ü–∞—Ä–∞–º–µ—Ç—Ä—ã: {gs.best_params_}")
        tuned_models.append((name, gs.best_estimator_))

    # ‚úÖ –û–±—É—á–∞–µ–º —Å—Ç–µ–∫–∏–Ω–≥: CatBoost + XGBoost + LogisticRegression
    logger.info("‚úÖ –û–±—É—á–µ–Ω–∏–µ StackingClassifier...")
    estimators = [
        ("cat", [m for name, m in tuned_models if name == "catboost"][0]),
        ("xgb", [m for name, m in tuned_models if name == "xgboost"][0])
    ]
    final_estimator = LogisticRegression(max_iter=1000, solver="liblinear")

    stack_model = StackingClassifier(
        estimators=estimators,
        final_estimator=final_estimator,
        cv=StratifiedKFold(n_splits=N_SPLITS_CV, shuffle=True, random_state=RANDOM_STATE),
        n_jobs=-1
    )

    stack_model.fit(X_df, y)

    # –°—Ä–∞–≤–Ω–µ–Ω–∏–µ –º–æ–¥–µ–ª–µ–π
    logger.info("üìä –°—Ä–∞–≤–Ω–µ–Ω–∏–µ –º–æ–¥–µ–ª–µ–π (Stacking vs XGBoost vs CatBoost)...")

    models_to_compare = {
        "stack": stack_model,
        "xgboost": [m for name, m in tuned_models if name == "xgboost"][0],
        "catboost": [m for name, m in tuned_models if name == "catboost"][0],
    }

    results = {}
    for name, model in models_to_compare.items():
        model.fit(X_df, y)
        y_prob = model.predict_proba(X_df)[:, 1]
        auc = roc_auc_score(y, y_prob)
        results[name] = auc
        logger.info(f"{name} ROC AUC = {auc:.4f}")

    best_model_name = max(results, key=results.get)
    best_model = models_to_compare[best_model_name]
    logger.info(f"‚úÖ –í—ã–±—Ä–∞–Ω–∞ –ª—É—á—à–∞—è –º–æ–¥–µ–ª—å: {best_model_name.upper()} (ROC AUC = {results[best_model_name]:.4f})")


    # –ü–µ—Ä–µ–æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ X_df –ø–æ –æ—Ç–æ–±—Ä–∞–Ω–Ω—ã–º SHAP –ø—Ä–∏–∑–Ω–∞–∫–∞–º
    X_df = X_df[selected_features].copy()
    logger.info(f"‚öôÔ∏è –ò—Å–ø–æ–ª—å–∑—É—é—Ç—Å—è {len(X_df.columns)} –ø—Ä–∏–∑–Ω–∞–∫–∏ –∏–∑ SHAP.")


    # –ü–æ–≤—Ç–æ—Ä–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ —Ñ–∏–Ω–∞–ª—å–Ω–æ–π –º–æ–¥–µ–ª–∏ –Ω–∞ –≤—Å—ë–º –¥–∞—Ç–∞—Å–µ—Ç–µ
    logger.info("–û–±—É—á–µ–Ω–∏–µ —Ñ–∏–Ω–∞–ª—å–Ω–æ–π –º–æ–¥–µ–ª–∏ –Ω–∞ –≤—Å—ë–º –¥–∞—Ç–∞—Å–µ—Ç–µ (SHAP-–ø—Ä–∏–∑–Ω–∞–∫–∏)...")
    best_model.fit(X_df, y)




    # === –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è
    y_pred = best_model.predict(X_df)
    y_proba = best_model.predict_proba(X_df)[:, 1]

    # === –ú–µ—Ç—Ä–∏–∫–∏
    roc_auc = roc_auc_score(y, y_proba)
    acc = accuracy_score(y, y_pred)
    prec = precision_score(y, y_pred)
    rec = recall_score(y, y_pred)
    f1 = f1_score(y, y_pred)
    logger.info(f"=== –§–∏–Ω–∞–ª—å–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏ (OOF, full data) ===")
    logger.info(f"ROC AUC:  {roc_auc:.4f}")
    logger.info(f"Accuracy: {acc:.4f}")
    logger.info(f"Precision: {prec:.4f}")
    logger.info(f"Recall:    {rec:.4f}")
    logger.info(f"F1-score:  {f1:.4f}")

    # === Classification report & confusion matrix
    logger.info("\n" + classification_report(y, y_pred))
    logger.info(f"\nConfusion matrix:\n{confusion_matrix(y, y_pred)}")


    # === ROC-–∫—Ä–∏–≤–∞—è
    fpr, tpr, _ = roc_curve(y, y_proba)
    plt.figure(figsize=(6, 6))
    plt.plot(fpr, tpr, label=f"ROC AUC = {roc_auc:.3f}")
    plt.plot([0, 1], [0, 1], linestyle="--")
    plt.xlabel("False Positive Rate")
    plt.ylabel("True Positive Rate")
    plt.title("ROC Curve ‚Äî Final Model")
    plt.legend()
    roc_path = os.path.join(PLOTS_DIR, f"{TASK_NAME}_OOF_Best_{best_model_name}_roc_curve.png")
    plt.savefig(roc_path)
    logger.info(f"ROC-–∫—Ä–∏–≤–∞—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞: {roc_path}")



    # === Hold-out –≤–∞–ª–∏–¥–∞—Ü–∏—è (20%)


    logger.info("–ü—Ä–æ–≤–µ—Ä–∫–∞ –º–æ–¥–µ–ª–∏ –Ω–∞ –æ—Ç–ª–æ–∂–µ–Ω–Ω–æ–π –≤—ã–±–æ—Ä–∫–µ (hold-out 20%)...")

    X_train, X_test, y_train, y_test = train_test_split(
        X_df, y, test_size=0.2, random_state=RANDOM_STATE, stratify=y
    )

    # –ü–µ—Ä–µ–æ–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏ –Ω–∞ —Ç—Ä–µ–Ω–∏—Ä–æ–≤–æ—á–Ω–æ–π –≤—ã–±–æ—Ä–∫–µ
    best_model.fit(X_train, y_train)

    # –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è
    y_test_pred = best_model.predict(X_test)
    y_test_proba = best_model.predict_proba(X_test)[:, 1]

    # –ú–µ—Ç—Ä–∏–∫–∏ hold-out
    roc_auc_holdout = roc_auc_score(y_test, y_test_proba)
    acc_holdout = accuracy_score(y_test, y_test_pred)
    prec_holdout = precision_score(y_test, y_test_pred)
    rec_holdout = recall_score(y_test, y_test_pred)
    f1_holdout = f1_score(y_test, y_test_pred)

    logger.info(f"=== Hold-out –º–µ—Ç—Ä–∏–∫–∏ (Test 20%) ===")
    logger.info(f"ROC AUC:  {roc_auc_holdout:.4f}")
    logger.info(f"Accuracy: {acc_holdout:.4f}")
    logger.info(f"Precision: {prec_holdout:.4f}")
    logger.info(f"Recall:    {rec_holdout:.4f}")
    logger.info(f"F1-score:  {f1_holdout:.4f}")

    # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ hold-out –º–µ—Ç—Ä–∏–∫
    metrics_holdout_path = os.path.join(MODELS_DIR, f"metrics_{best_model_name}_holdout.txt")
    with open(metrics_holdout_path, "w") as f:
        f.write(f"ROC AUC:  {roc_auc_holdout:.4f}\n")
        f.write(f"Accuracy: {acc_holdout:.4f}\n")
        f.write(f"Precision: {prec_holdout:.4f}\n")
        f.write(f"Recall:    {rec_holdout:.4f}\n")
        f.write(f"F1-score:  {f1_holdout:.4f}\n")

    logger.info(f"Hold-out –º–µ—Ç—Ä–∏–∫–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã: {metrics_holdout_path}")






    logger.info("üìä –°—Ä–∞–≤–Ω–µ–Ω–∏–µ —Å –±–∞–∑–æ–≤—ã–º–∏ –º–æ–¥–µ–ª—è–º–∏ –Ω–∞ hold-out...")

    base_models = {
        "RandomForest": RandomForestClassifier(n_estimators=100, random_state=42),
        "LogisticRegression": LogisticRegression(max_iter=1000, solver="liblinear")
    }

    for name, model in base_models.items():
        model.fit(X_train, y_train)
        preds = model.predict_proba(X_test)[:, 1]
        roc = roc_auc_score(y_test, preds)
        acc = accuracy_score(y_test, preds > 0.5)
        logger.info(f"{name} ROC AUC: {roc:.4f}, Accuracy: {acc:.4f}")






    # === SHAP-–∞–Ω–∞–ª–∏–∑
    logger.info("SHAP-–∞–Ω–∞–ª–∏–∑...")

    model_for_shap = best_model.named_steps["classifier"]
    if isinstance(model_for_shap, StackingClassifier):
        logger.warning("‚ùå SHAP –Ω–µ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç StackingClassifier –Ω–∞–ø—Ä—è–º—É—é ‚Äî –ø—Ä–æ–ø—É—Å–∫ –∞–Ω–∞–ª–∏–∑–∞")
        shap_supported = False
    else:
        try:
            explainer = shap.Explainer(model_for_shap)
            shap_values = explainer(X_df)
            shap_supported = True
        except Exception as e:
            logger.warning(f"‚ùå SHAP-–∞–Ω–∞–ª–∏–∑ –Ω–µ –≤—ã–ø–æ–ª–Ω–µ–Ω: {e}")
            shap_supported = False

    if shap_supported:
        # SHAP summary (bar)
        shap.summary_plot(shap_values, X_df, plot_type="bar", show=False)
        bar_path = os.path.join(PLOTS_DIR, f"{TASK_NAME}_SHAP_bar.png")
        plt.savefig(bar_path, bbox_inches="tight")
        plt.close()

        # SHAP summary (beeswarm)
        shap.summary_plot(shap_values, X_df, plot_type="violin", show=False)
        bee_path = os.path.join(PLOTS_DIR, f"{TASK_NAME}_SHAP_beeswarm.png")
        plt.savefig(bee_path, bbox_inches="tight")
        plt.close()

        logger.info(f"SHAP-–≥—Ä–∞—Ñ–∏–∫–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã: {bar_path}, {bee_path}")

        # === –û—Ç–±–æ—Ä –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –ø–æ SHAP
        threshold_val = np.quantile(np.abs(shap_values.values).mean(axis=0), 0.30)
        selector = SelectFromModel(model_for_shap, threshold=threshold_val, prefit=True)
        X_selected = selector.transform(X_df)
        selected_features = X_df.columns[selector.get_support()].tolist()


        X_df = pd.DataFrame(X_selected, columns=selected_features)
        logger.info(f"üîç –§–∏–Ω–∞–ª—å–Ω–æ–µ —á–∏—Å–ª–æ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –ø–æ—Å–ª–µ SHAP-–æ—Ç–±–æ—Ä–∞: {len(selected_features)}")


        # ‚úÖ –°–æ–∑–¥–∞–Ω–∏–µ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏, –µ—Å–ª–∏ –Ω–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç
        os.makedirs(FEATURES_DIR, exist_ok=True)

        features_path = os.path.join(FEATURES_DIR, f"selected_by_shap_{TASK_NAME}.txt")
        pd.Series(selected_features).to_csv(features_path, index=False)
        logger.info(f"–°–æ—Ö—Ä–∞–Ω–µ–Ω–æ {len(selected_features)} –ø—Ä–∏–∑–Ω–∞–∫–æ–≤: {features_path}")


    # === –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏
    model_path = os.path.join(MODELS_DIR, f"model_{TASK_NAME}_{best_model_name}.joblib")
    joblib.dump(best_model, model_path)
    logger.info(f"–ú–æ–¥–µ–ª—å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞: {model_path}")

    # === –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ü–µ–ª–µ–≤–æ–π –ø–µ—Ä–µ–º–µ–Ω–Ω–æ–π
    y.to_csv(os.path.join(MODELS_DIR, "target.csv"), index=False)

    # === –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –º–µ—Ç—Ä–∏–∫
    metrics_path = os.path.join(MODELS_DIR, f"metrics_{best_model_name}.txt")
    with open(metrics_path, "w") as f:
        f.write(f"ROC AUC:  {roc_auc:.4f}\n")
        f.write(f"Accuracy: {acc:.4f}\n")
        f.write(f"Precision: {prec:.4f}\n")
        f.write(f"Recall:    {rec:.4f}\n")
        f.write(f"F1-score:  {f1:.4f}\n")
    logger.info(f"–ú–µ—Ç—Ä–∏–∫–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã: {metrics_path}")


    # === üìà –ì—Ä–∞—Ñ–∏–∫ –ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∏—è: OOF vs Hold-out ===


    # –ó–Ω–∞—á–µ–Ω–∏—è
    oof_auc = roc_auc      # –∏–∑ —Ñ–∏–Ω–∞–ª—å–Ω–æ–π –º–æ–¥–µ–ª–∏
    holdout_auc = roc_auc_holdout  # –∏–∑ hold-out —Ç–µ—Å—Ç–∞

    # –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è
    plt.figure(figsize=(6, 4))
    bars = plt.bar(["OOF (Train CV)", "Hold-out (Test)"], [oof_auc, holdout_auc],
                color=["#1f77b4", "#ff7f0e"])

    # –ü–æ–¥–ø–∏—Å–∏ –∑–Ω–∞—á–µ–Ω–∏–π
    for bar in bars:
        yval = bar.get_height()
        plt.text(bar.get_x() + bar.get_width()/2.0, yval + 0.01, f"{yval:.4f}", ha='center', va='bottom')

    # –ù–∞—Å—Ç—Ä–æ–π–∫–∏
    plt.ylim(0.0, 1.05)
    plt.ylabel("ROC AUC")
    plt.title("Train vs Hold-out ROC AUC")
    plt.grid(True, axis='y')
    plt.tight_layout()

    # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ
    plt.savefig(os.path.join(PLOTS_DIR, f"{TASK_NAME}_overfitting_check_auc.png"))
    plt.close()


    # ROC-–∫—Ä–∏–≤–∞—è –Ω–∞ hold-out (XGBoost)
    fpr, tpr, _ = roc_curve(y_test, y_test_proba)
    plt.figure(figsize=(6, 6))
    plt.plot(fpr, tpr, label=f"XGBoost (AUC = {roc_auc_score(y_test, y_test_proba):.3f})")
    plt.plot([0, 1], [0, 1], 'k--', alpha=0.5)
    plt.xlabel("False Positive Rate")
    plt.ylabel("True Positive Rate")
    plt.title("ROC-–∫—Ä–∏–≤–∞—è (Hold-out)")
    plt.legend()
    roc_path = os.path.join(PLOTS_DIR, f"{TASK_NAME}_holdout_ROC.png")
    plt.savefig(roc_path)
    plt.close()
    logger.info(f"‚úÖ ROC-–∫—Ä–∏–≤–∞—è –Ω–∞ hold-out —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞: {roc_path}")






if __name__ == "__main__":
    run_clf_si_median()