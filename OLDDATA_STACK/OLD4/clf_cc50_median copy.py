import os
import joblib
import shap
import logging
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt

from sklearn.metrics import precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix, accuracy_score, roc_curve
from sklearn.ensemble import RandomForestClassifier


from sklearn.model_selection import StratifiedKFold, GridSearchCV, cross_val_predict, cross_val_score, train_test_split
from sklearn.metrics import precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix
from sklearn.preprocessing import StandardScaler, RobustScaler
from sklearn.feature_selection import SelectKBest, mutual_info_classif, SelectFromModel
from sklearn.pipeline import make_pipeline, Pipeline
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import StackingClassifier
from catboost import CatBoostClassifier
from xgboost import XGBClassifier
from utils import (
    load_prepared_data,
    save_model_artifacts,
    setup_logging,
    get_logger,
    plot_roc_curve,
    PLOTS_DIR,
    RANDOM_STATE,
    N_SPLITS_CV
)

setup_logging()
logger = get_logger(__name__)

# –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –≠–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–∞
TARGET_CC50_COLUMN = 'CC50_nM'
USE_FEATURE_SELECTION = True
N_TOP_FEATURES_TO_SELECT = 99
TASK_NAME = "clf_cc50_median"
TUNE_BASE_MODELS = True

DATA_FILE = "data/eda_gen/data_final.csv"
FEATURES_FILE = "data/eda_gen/features/clf_CC50_gt_median.txt"  # –ù–æ–≤—ã–π —Ñ–∞–π–ª –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –¥–ª—è CC50
MODELS_DIR = f"models/{TASK_NAME}"

# –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –∏–º–µ–Ω–∏ –∑–∞–¥–∞—á–∏
task_identifier = TARGET_CC50_COLUMN.lower().replace("_", "")
TASK_NAME_PREFIX = f'clf_{task_identifier}_median'
TASK_NAME = f'{TASK_NAME_PREFIX}'
if USE_FEATURE_SELECTION:
    TASK_NAME += f'_mi_top{N_TOP_FEATURES_TO_SELECT}'
else:
    TASK_NAME += '_allfeatures'
if TUNE_BASE_MODELS:
    TASK_NAME += '_tuned_stack'

TASK_PLOTS_DIR = os.path.join(PLOTS_DIR, "classification", TASK_NAME)
os.makedirs(TASK_PLOTS_DIR, exist_ok=True)

# –û—Å–Ω–æ–≤–Ω–∞—è –ª–æ–≥–∏–∫–∞
def main():
    logger.info(f"--- –ù–∞—á–∞–ª–æ –∑–∞–¥–∞—á–∏: {TASK_NAME} ---")

    # –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö
    df_full = pd.read_csv(DATA_FILE)
    logger.info(f"‚úÖ –î–∞–Ω–Ω—ã–µ –∑–∞–≥—Ä—É–∂–µ–Ω—ã: {df_full.shape}")

    # –ë–∏–Ω–∞—Ä–∏–∑–∞—Ü–∏—è —Ç–∞—Ä–≥–µ—Ç–∞
    median_val = df_full[TARGET_CC50_COLUMN].median()
    y = (df_full[TARGET_CC50_COLUMN] > median_val).astype(int)
    y.name = "target"
    logger.info(f"üéØ –¶–µ–ª—å: {TARGET_CC50_COLUMN} > {median_val:.2f}, –±–∞–ª–∞–Ω—Å –∫–ª–∞—Å—Å–æ–≤:\n{y.value_counts(normalize=True).rename('proportion')}")

    # –£–¥–∞–ª–µ–Ω–∏–µ –ø–æ—Ç–µ–Ω—Ü–∏–∞–ª—å–Ω—ã—Ö —É—Ç–µ—á–µ–∫
    forbidden_cols = [
        "CC50", "CC50_mM", "CC50_nM", "log_CC50", "log1p_CC50", "log1p_CC50_nM", "CC50_gt_median",
        "IC50", "IC50_mM", "IC50_nM", "log_IC50", "log1p_IC50", "log1p_IC50_nM", "IC50_gt_median",
        "SI", "SI_corrected", "log_SI", "log1p_SI", "log1p_SI_corrected",
        "SI_original", "SI_diff", "SI_diff_check", "SI_check", "SI_gt_median", "SI_gt_8",
        "ratio_IC50_CC50", "Unnamed: 0"
    ]
    X_full = df_full.drop(columns=forbidden_cols, errors="ignore")
    logger.info(f"–£–¥–∞–ª–µ–Ω—ã –ø–æ—Ç–µ–Ω—Ü–∏–∞–ª—å–Ω–æ —É—Ç–µ—á–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏: {[col for col in forbidden_cols if col in df_full.columns]}")

    # –ó–∞–≥—Ä—É–∑–∫–∞ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
    if not os.path.exists(FEATURES_FILE):
        logger.error(f"‚ùå –§–∞–π–ª –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –Ω–µ –Ω–∞–π–¥–µ–Ω: {FEATURES_FILE}")
        return
    with open(FEATURES_FILE, "r") as f:
        selected_features = [line.strip() for line in f if line.strip() in X_full.columns]

    selected_features = selected_features[:N_TOP_FEATURES_TO_SELECT]
    logger.info(f"‚úÖ –ò—Å–ø–æ–ª—å–∑—É—é—Ç—Å—è –ø—Ä–∏–∑–Ω–∞–∫–∏ (top-{N_TOP_FEATURES_TO_SELECT}): {len(selected_features)}")
    X = X_full[selected_features].copy()

    # –°–æ–∑–¥–∞–Ω–∏–µ X_df
    X_df = X.copy()


    # === –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ª—É—á—à–µ–≥–æ —á–∏—Å–ª–∞ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ —Å –∫—Ä–æ—Å—Å-–≤–∞–ª–∏–¥–∞—Ü–∏–µ–π ---
    logger.info("üîç –ü–æ–∏—Å–∫ –æ–ø—Ç–∏–º–∞–ª—å–Ω–æ–≥–æ —á–∏—Å–ª–∞ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤...")

    cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=RANDOM_STATE)
    max_k = 99  # –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
    roc_scores = []  # –°–ø–∏—Å–æ–∫ –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤

    # –¶–∏–∫–ª –ø–æ –∫–æ–ª–∏—á–µ—Å—Ç–≤—É –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
    for k in range(10, max_k + 1, 10):
        selector = SelectKBest(score_func=mutual_info_classif, k=k)
        X_k = selector.fit_transform(X, y)  # –ü—Ä–∏–º–µ–Ω–µ–Ω–∏–µ –≤—ã–±–æ—Ä–∞ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
        pipe = make_pipeline(StandardScaler(), CatBoostClassifier(verbose=0, random_state=RANDOM_STATE))  # –ü–∞–π–ø–ª–∞–π–Ω
        score = cross_val_score(pipe, X_k, y, cv=cv, scoring="roc_auc", n_jobs=-1).mean()  # –ö—Ä–æ—Å—Å-–≤–∞–ª–∏–¥–∞—Ü–∏—è
        roc_scores.append((k, score))  # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
        logger.info(f"k = {k}, ROC AUC = {score:.4f}")

    # –ü–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ –≥—Ä–∞—Ñ–∏–∫–∞ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –∫–∞—á–µ—Å—Ç–≤–∞ –æ—Ç –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
    ks, scores = zip(*roc_scores)  # –†–∞–∑–¥–µ–ª–µ–Ω–∏–µ –Ω–∞ k –∏ roc_auc
    plt.figure(figsize=(8, 5))
    plt.plot(ks, scores, marker="o")
    plt.xlabel("–ß–∏—Å–ª–æ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ (k)")
    plt.ylabel("ROC AUC (CV)")
    plt.title("–ü–æ–¥–±–æ—Ä –æ–ø—Ç–∏–º–∞–ª—å–Ω–æ–≥–æ –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤")
    plt.grid(True)
    plt.tight_layout()

    # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –≥—Ä–∞—Ñ–∏–∫–∞
    roc_curve_path = os.path.join(PLOTS_DIR, f"{TASK_NAME}_feature_selection_curve.png")
    plt.savefig(roc_curve_path)
    logger.info(f"–ì—Ä–∞—Ñ–∏–∫ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –∫–∞—á–µ—Å—Ç–≤–∞ –æ—Ç —á–∏—Å–ª–∞ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ —Å–æ—Ö—Ä–∞–Ω–µ–Ω: {roc_curve_path}")
    plt.close()




    # MI –æ—Ç–±–æ—Ä –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
    if USE_FEATURE_SELECTION:
        selector = SelectKBest(score_func=mutual_info_classif, k="all")
        selector.fit(X, y)
        mi_scores = pd.Series(selector.scores_, index=X.columns).sort_values(ascending=False)
        selected_features = mi_scores.head(N_TOP_FEATURES_TO_SELECT).index.tolist()
        X = X[selected_features]
        logger.info(f"üìä MI –æ—Ç–±–æ—Ä: –≤—ã–±—Ä–∞–Ω–æ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤: {len(selected_features)}")

    # A/B —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –¥–≤—É—Ö —Å–∫–µ–π–ª–µ—Ä–æ–≤
    logger.info("üîç A/B-—Ç–µ—Å—Ç —Å–∫–µ–π–ª–µ—Ä–æ–≤: StandardScaler vs RobustScaler...")

    cv = StratifiedKFold(n_splits=N_SPLITS_CV, shuffle=True, random_state=RANDOM_STATE)
    scalers = {
        "StandardScaler": StandardScaler(),
        "RobustScaler": RobustScaler()
    }

    best_scaler_name = None
    best_roc_auc = -np.inf
    best_scaler = None

    for name, scaler in scalers.items():
        pipe = make_pipeline(
            scaler,
            CatBoostClassifier(verbose=0, random_state=RANDOM_STATE)
        )
        roc_auc = cross_val_score(pipe, X, y, cv=cv, scoring="roc_auc", n_jobs=-1).mean()
        logger.info(f"ROC AUC ({name}): {roc_auc:.4f}")
        
        if roc_auc > best_roc_auc:
            best_roc_auc = roc_auc
            best_scaler_name = name
            best_scaler = scaler

    logger.info(f"‚úÖ –í—ã–±—Ä–∞–Ω –ª—É—á—à–∏–π —Å–∫–µ–π–ª–µ—Ä: {best_scaler_name} (ROC AUC = {best_roc_auc:.4f})")

    # –ü–æ–¥—Å—á—ë—Ç class_weights –≤—Ä—É—á–Ω—É—é –¥–ª—è CC50
    class_counts = y.value_counts()
    total = len(y)
    class_weights = [
        total / (2 * class_counts[0]),
        total / (2 * class_counts[1])
    ]

    # –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –¥–ª—è CatBoost
    param_grid_catboost = {
        "classifier__iterations": [200, 400, 600],
        "classifier__depth": [4, 6, 8],
        "classifier__learning_rate": [0.01, 0.03, 0.05, 0.1]
    }

    # –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –¥–ª—è XGBoost
    param_grid_xgboost = {
        "classifier__n_estimators": [200, 400, 600],
        "classifier__max_depth": [3, 5, 7],
        "classifier__learning_rate": [0.01, 0.03, 0.05],
        "classifier__subsample": [0.7, 0.9, 1.0],
        "classifier__colsample_bytree": [0.7, 0.9, 1.0]
    }

    # –°–ø–∏—Å–æ–∫ –º–æ–¥–µ–ª–µ–π —Å –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏ –¥–ª—è GridSearch
    models = {
        "catboost": {
            "model": CatBoostClassifier(
                verbose=0,
                random_state=RANDOM_STATE,
                class_weights=class_weights,
                l2_leaf_reg=10.0  # —Ä–µ–≥—É–ª—è—Ä–∏–∑–∞—Ü–∏—è –¥–ª—è –±–æ—Ä—å–±—ã —Å –ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∏–µ–º
            ),
            "params": param_grid_catboost
        },
        "xgboost": {
            "model": XGBClassifier(
                eval_metric="logloss",
                random_state=RANDOM_STATE
            ),
            "params": param_grid_xgboost
        }
    }

    tuned_models = []

    # –¢—é–Ω–∏–Ω–≥ –±–∞–∑–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π
    for name, config in models.items():
        logger.info(f"–¢—é–Ω–∏–Ω–≥ –º–æ–¥–µ–ª–∏: {name}")
        pipe = Pipeline([
            ("scaler", best_scaler),
            ("classifier", config["model"])
        ])

        # –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –¥–ª—è GridSearchCV
        gs = GridSearchCV(
            pipe, config["params"],
            cv=StratifiedKFold(n_splits=N_SPLITS_CV, shuffle=True, random_state=RANDOM_STATE),
            scoring="roc_auc", n_jobs=-1, verbose=1
        )

        # –û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏ —Å –ø–æ–¥–±–æ—Ä–æ–º –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤
        gs.fit(X, y)
        logger.info(f"Best ROC AUC {name}: {gs.best_score_:.4f}, –ü–∞—Ä–∞–º–µ—Ç—Ä—ã: {gs.best_params_}")
        tuned_models.append((name, gs.best_estimator_))

    # –°—Ç–µ–∫–∫–∏–Ω–≥
    # –û–±—É—á–µ–Ω–∏–µ StackingClassifier
    final_estimator = LogisticRegression(max_iter=1000, solver="liblinear")
    stack_model = StackingClassifier(
        estimators=[("cat", tuned_models[0][1]), ("xgb", tuned_models[1][1])],
        final_estimator=final_estimator,
        cv=StratifiedKFold(n_splits=N_SPLITS_CV, shuffle=True, random_state=RANDOM_STATE),
        n_jobs=-1
    )

    stack_model.fit(X, y)




    # –°—Ä–∞–≤–Ω–µ–Ω–∏–µ –º–æ–¥–µ–ª–µ–π
    logger.info("üìä –°—Ä–∞–≤–Ω–µ–Ω–∏–µ –º–æ–¥–µ–ª–µ–π (Stacking vs XGBoost vs CatBoost)...")
    models_to_compare = {
        "stack": stack_model,
        "xgboost": [m for name, m in tuned_models if name == "xgboost"][0],
        "catboost": [m for name, m in tuned_models if name == "catboost"][0],
    }

    results = {}
    for name, model in models_to_compare.items():
        model.fit(X_df, y)
        y_prob = model.predict_proba(X_df)[:, 1]
        auc = roc_auc_score(y, y_prob)
        results[name] = auc
        logger.info(f"{name} ROC AUC = {auc:.4f}")

        # –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –¥–ª—è confusion_matrix
        y_pred = model.predict(X_df)
        cm = confusion_matrix(y, y_pred)
        logger.info(f"{name} Confusion Matrix:\n{cm}")

    best_model_name = max(results, key=results.get)
    best_model = models_to_compare[best_model_name]
    logger.info(f"‚úÖ –í—ã–±—Ä–∞–Ω–∞ –ª—É—á—à–∞—è –º–æ–¥–µ–ª—å: {best_model_name.upper()} (ROC AUC = {results[best_model_name]:.4f})")


    # –ü–æ–≤—Ç–æ—Ä–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ —Ñ–∏–Ω–∞–ª—å–Ω–æ–π –º–æ–¥–µ–ª–∏ –Ω–∞ –≤—Å—ë–º –¥–∞—Ç–∞—Å–µ—Ç–µ
    logger.info("–û–±—É—á–µ–Ω–∏–µ —Ñ–∏–Ω–∞–ª—å–Ω–æ–π –º–æ–¥–µ–ª–∏ –Ω–∞ –≤—Å—ë–º –¥–∞—Ç–∞—Å–µ—Ç–µ...")
    best_model.fit(X_df, y)

    # –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è
    y_pred = best_model.predict(X_df)
    y_proba = best_model.predict_proba(X_df)[:, 1]

    # –ú–µ—Ç—Ä–∏–∫–∏
    y_pred = best_model.predict(X_df)
    y_proba = best_model.predict_proba(X_df)[:, 1]

    roc_auc = roc_auc_score(y, y_proba)
    acc = accuracy_score(y, y_pred)
    prec = precision_score(y, y_pred)
    rec = recall_score(y, y_pred)
    f1 = f1_score(y, y_pred)
    logger.info(f"=== –§–∏–Ω–∞–ª—å–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏ (OOF, full data) ===")
    logger.info(f"ROC AUC:  {roc_auc:.4f}")
    logger.info(f"Accuracy: {acc:.4f}")
    logger.info(f"Precision: {prec:.4f}")
    logger.info(f"Recall:    {rec:.4f}")
    logger.info(f"F1-score:  {f1:.4f}")



    # === ROC-–∫—Ä–∏–≤–∞—è
    fpr, tpr, _ = roc_curve(y, y_proba)
    plt.figure(figsize=(6, 6))
    plt.plot(fpr, tpr, label=f"ROC AUC = {roc_auc:.3f}")
    plt.plot([0, 1], [0, 1], linestyle="--")
    plt.xlabel("False Positive Rate")
    plt.ylabel("True Positive Rate")
    plt.title("ROC Curve ‚Äî Final Model")
    plt.legend()
    roc_path = os.path.join(PLOTS_DIR, f"{TASK_NAME}_OOF_Best_{best_model_name}_roc_curve.png")
    plt.savefig(roc_path)
    logger.info(f"ROC-–∫—Ä–∏–≤–∞—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞: {roc_path}")




    # === Hold-out –≤–∞–ª–∏–¥–∞—Ü–∏—è (20%)

    logger.info("–ü—Ä–æ–≤–µ—Ä–∫–∞ –º–æ–¥–µ–ª–∏ –Ω–∞ –æ—Ç–ª–æ–∂–µ–Ω–Ω–æ–π –≤—ã–±–æ—Ä–∫–µ (hold-out 20%)...")

    # –†–∞–∑–¥–µ–ª–µ–Ω–∏–µ –Ω–∞ —Ç—Ä–µ–Ω–∏—Ä–æ–≤–æ—á–Ω—É—é –∏ —Ç–µ—Å—Ç–æ–≤—É—é –≤—ã–±–æ—Ä–∫—É
    X_train, X_test, y_train, y_test = train_test_split(
        X_df, y, test_size=0.2, random_state=RANDOM_STATE, stratify=y
    )

    # –ü–µ—Ä–µ–æ–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏ –Ω–∞ —Ç—Ä–µ–Ω–∏—Ä–æ–≤–æ—á–Ω–æ–π –≤—ã–±–æ—Ä–∫–µ
    best_model.fit(X_train, y_train)

    # –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –Ω–∞ —Ç–µ—Å—Ç–æ–≤–æ–π –≤—ã–±–æ—Ä–∫–µ
    y_test_pred = best_model.predict(X_test)
    y_test_proba = best_model.predict_proba(X_test)[:, 1]

    # –ú–µ—Ç—Ä–∏–∫–∏ hold-out
    roc_auc_holdout = roc_auc_score(y_test, y_test_proba)
    acc_holdout = accuracy_score(y_test, y_test_pred)
    prec_holdout = precision_score(y_test, y_test_pred)
    rec_holdout = recall_score(y_test, y_test_pred)
    f1_holdout = f1_score(y_test, y_test_pred)

    logger.info(f"=== Hold-out –º–µ—Ç—Ä–∏–∫–∏ (Test 20%) ===")
    logger.info(f"ROC AUC:  {roc_auc_holdout:.4f}")
    logger.info(f"Accuracy: {acc_holdout:.4f}")
    logger.info(f"Precision: {prec_holdout:.4f}")
    logger.info(f"Recall:    {rec_holdout:.4f}")
    logger.info(f"F1-score:  {f1_holdout:.4f}")

    # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ hold-out –º–µ—Ç—Ä–∏–∫
    metrics_holdout_path = os.path.join(MODELS_DIR, f"metrics_{best_model_name}_holdout.txt")
    os.makedirs(MODELS_DIR, exist_ok=True)  # –°–æ–∑–¥–∞–Ω–∏–µ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏ –¥–ª—è –º–æ–¥–µ–ª–µ–π, –µ—Å–ª–∏ –æ–Ω–∞ –Ω–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç
    with open(metrics_holdout_path, "w") as f:
        f.write(f"ROC AUC:  {roc_auc_holdout:.4f}\n")
        f.write(f"Accuracy: {acc_holdout:.4f}\n")
        f.write(f"Precision: {prec_holdout:.4f}\n")
        f.write(f"Recall:    {rec_holdout:.4f}\n")
        f.write(f"F1-score:  {f1_holdout:.4f}\n")

    logger.info(f"Hold-out –º–µ—Ç—Ä–∏–∫–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã: {metrics_holdout_path}")

    # –°—Ä–∞–≤–Ω–µ–Ω–∏–µ —Å –±–∞–∑–æ–≤—ã–º–∏ –º–æ–¥–µ–ª—è–º–∏ –Ω–∞ hold-out
    logger.info("üìä –°—Ä–∞–≤–Ω–µ–Ω–∏–µ —Å –±–∞–∑–æ–≤—ã–º–∏ –º–æ–¥–µ–ª—è–º–∏ –Ω–∞ hold-out...")

    base_models = {
        "RandomForest": RandomForestClassifier(n_estimators=100, random_state=42),
        "LogisticRegression": LogisticRegression(max_iter=1000, solver="liblinear")
    }

    for name, model in base_models.items():
        model.fit(X_train, y_train)
        preds = model.predict_proba(X_test)[:, 1]
        roc = roc_auc_score(y_test, preds)
        acc = accuracy_score(y_test, preds > 0.5)
        logger.info(f"{name} ROC AUC: {roc:.4f}, Accuracy: {acc:.4f}")

    # === SHAP-–∞–Ω–∞–ª–∏–∑
    logger.info("SHAP-–∞–Ω–∞–ª–∏–∑...")

    model_for_shap = best_model.named_steps["classifier"]
    shap_supported = False  # –ò–∑–Ω–∞—á–∞–ª—å–Ω–æ —É—Å—Ç–∞–Ω–æ–≤–∫–∞ –Ω–∞ False
    if isinstance(model_for_shap, StackingClassifier):
        logger.warning("‚ùå SHAP –Ω–µ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç StackingClassifier –Ω–∞–ø—Ä—è–º—É—é ‚Äî –ø—Ä–æ–ø—É—Å–∫ –∞–Ω–∞–ª–∏–∑–∞")
    else:
        try:
            explainer = shap.Explainer(model_for_shap)
            shap_values = explainer(X_df)
            shap_supported = True
        except Exception as e:
            logger.warning(f"‚ùå SHAP-–∞–Ω–∞–ª–∏–∑ –Ω–µ –≤—ã–ø–æ–ª–Ω–µ–Ω: {e}")

    if shap_supported:
        # SHAP summary (bar)
        shap.summary_plot(shap_values, X_df, plot_type="bar", show=False)
        bar_path = os.path.join(PLOTS_DIR, f"{TASK_NAME}_SHAP_bar.png")
        plt.savefig(bar_path, bbox_inches="tight")
        plt.close()

        # SHAP summary (beeswarm)
        shap.summary_plot(shap_values, X_df, plot_type="violin", show=False)
        bee_path = os.path.join(PLOTS_DIR, f"{TASK_NAME}_SHAP_beeswarm.png")
        plt.savefig(bee_path, bbox_inches="tight")
        plt.close()

        logger.info(f"SHAP-–≥—Ä–∞—Ñ–∏–∫–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã: {bar_path}, {bee_path}")

        # === –û—Ç–±–æ—Ä –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –ø–æ SHAP
        threshold_val = np.quantile(np.abs(shap_values.values).mean(axis=0), 0.30)
        selector = SelectFromModel(model_for_shap, threshold=threshold_val, prefit=True)
        X_selected = selector.transform(X_df)
        selected_features = X_df.columns[selector.get_support()].tolist()

        X_df = pd.DataFrame(X_selected, columns=selected_features)
        logger.info(f"üîç –§–∏–Ω–∞–ª—å–Ω–æ–µ —á–∏—Å–ª–æ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –ø–æ—Å–ª–µ SHAP-–æ—Ç–±–æ—Ä–∞: {len(selected_features)}")

        # ‚úÖ –°–æ–∑–¥–∞–Ω–∏–µ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏, –µ—Å–ª–∏ –Ω–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç
        FEATURES_DIR = "features"
        os.makedirs(FEATURES_DIR, exist_ok=True)

        features_path = os.path.join(FEATURES_DIR, f"selected_by_shap_{TASK_NAME}.txt")
        pd.Series(selected_features).to_csv(features_path, index=False)
        logger.info(f"–°–æ—Ö—Ä–∞–Ω–µ–Ω–æ {len(selected_features)} –ø—Ä–∏–∑–Ω–∞–∫–æ–≤: {features_path}")

    # === –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏
    model_path = os.path.join(MODELS_DIR, f"model_{TASK_NAME}_{best_model_name}.joblib")
    joblib.dump(best_model, model_path)
    logger.info(f"–ú–æ–¥–µ–ª—å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞: {model_path}")

    # === –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ü–µ–ª–µ–≤–æ–π –ø–µ—Ä–µ–º–µ–Ω–Ω–æ–π
    y.to_csv(os.path.join(MODELS_DIR, "target.csv"), index=False)

    # === –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –º–µ—Ç—Ä–∏–∫
    metrics_path = os.path.join(MODELS_DIR, f"metrics_{best_model_name}.txt")
    with open(metrics_path, "w") as f:
        f.write(f"ROC AUC:  {roc_auc:.4f}\n")
        f.write(f"Accuracy: {acc:.4f}\n")
        f.write(f"Precision: {prec:.4f}\n")
        f.write(f"Recall:    {rec:.4f}\n")
        f.write(f"F1-score:  {f1:.4f}\n")
    logger.info(f"–ú–µ—Ç—Ä–∏–∫–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã: {metrics_path}")

    # === üìà –ì—Ä–∞—Ñ–∏–∫ –ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∏—è: OOF vs Hold-out ===

    # –ó–Ω–∞—á–µ–Ω–∏—è
    oof_auc = roc_auc  # –∏–∑ —Ñ–∏–Ω–∞–ª—å–Ω–æ–π –º–æ–¥–µ–ª–∏
    holdout_auc = roc_auc_holdout  # –∏–∑ hold-out —Ç–µ—Å—Ç–∞

    # –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è
    plt.figure(figsize=(6, 4))
    bars = plt.bar(["OOF (Train CV)", "Hold-out (Test)"], [oof_auc, holdout_auc],
                color=["#1f77b4", "#ff7f0e"])

    # –ü–æ–¥–ø–∏—Å–∏ –∑–Ω–∞—á–µ–Ω–∏–π
    for bar in bars:
        yval = bar.get_height()
        plt.text(bar.get_x() + bar.get_width() / 2.0, yval + 0.01, f"{yval:.4f}", ha='center', va='bottom')

    # –ù–∞—Å—Ç—Ä–æ–π–∫–∏
    plt.ylim(0.0, 1.05)
    plt.ylabel("ROC AUC")
    plt.title("Train vs Hold-out ROC AUC")
    plt.grid(True, axis='y')
    plt.tight_layout()

    # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ
    plt.savefig(os.path.join(PLOTS_DIR, f"{TASK_NAME}_overfitting_check_auc.png"))
    plt.close()

    # ROC-–∫—Ä–∏–≤–∞—è –Ω–∞ hold-out (XGBoost)
    fpr, tpr, _ = roc_curve(y_test, y_test_proba)
    plt.figure(figsize=(6, 6))
    plt.plot(fpr, tpr, label=f"XGBoost (AUC = {roc_auc_score(y_test, y_test_proba):.3f})")
    plt.plot([0, 1], [0, 1], 'k--', alpha=0.5)
    plt.xlabel("False Positive Rate")
    plt.ylabel("True Positive Rate")
    plt.title("ROC-–∫—Ä–∏–≤–∞—è (Hold-out)")
    plt.legend()
    roc_path = os.path.join(PLOTS_DIR, f"{TASK_NAME}_holdout_ROC.png")
    plt.savefig(roc_path)
    plt.close()
    logger.info(f"‚úÖ ROC-–∫—Ä–∏–≤–∞—è –Ω–∞ hold-out —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞: {roc_path}")



if __name__ == '__main__':
    main()
